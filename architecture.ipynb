{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b72584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import ConvLSTM2D, LSTM, BatchNormalization, Conv2D,Input, Dense, Reshape, Concatenate\n",
    "from keras.layers import Masking, InputLayer\n",
    "from utils.loss import masked_mse\n",
    "import numpy as np\n",
    "from utils.dataloader import dataloader\n",
    "from keras.utils import plot_model\n",
    "from utils import get_config\n",
    "from keras.layers import ConvLSTM2D, LSTM, BatchNormalization, Conv2D,Input, Dense, Reshape, Concatenate\n",
    "from keras.layers import Masking, Embedding\n",
    "from keras.layers import LayerNormalization, MultiHeadAttention, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ac3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvLSTM:\n",
    "\n",
    "    def __init__(self, x_iv_train, y_iv_train, \\\n",
    "                 x_iv_val=None, y_iv_val=None, config=None):\n",
    "        self.read_config(config) # Read the parameters and set the data\n",
    "        self.x_iv_train = x_iv_train\n",
    "        self.target_train = y_iv_train\n",
    "        self.x_iv_val = x_iv_val\n",
    "        self.target_val = y_iv_val\n",
    "\n",
    "    def read_config(self, config):\n",
    "\n",
    "        self.patience = config['training']['patience']\n",
    "        self.epsilon = config['training']['epsilon']\n",
    "        self.batch_size = config['training']['batch_size']\n",
    "        self.epochs = config['training']['epochs']\n",
    "        self.seed = config['training']['seed']\n",
    "        self.learning_rate = config['training']['lr']\n",
    "\n",
    "        self.window_size = config['data']['window_size']\n",
    "        self.run = config['data']['run']\n",
    "        self.covariate_columns = config['data']['covariates']\n",
    "        self.option_type = config['data']['option']\n",
    "        self.smooth = config['data']['smooth']\n",
    "        self.h_step = config['data']['h_step']\n",
    "\n",
    "        self.filters = config['model']['filters'] # 16 32 64 128 filter within the conv2DLSTM layer\n",
    "        self.kernel_height = config['model']['kernel_height']\n",
    "        self.kernel_width = config['model']['kernel_width'] # 1 to 5 (maturity) mxn -> 9x5\n",
    "        self.num_layer = config['model']['num_layer'] # Any positive integer >0\n",
    "        self.strides_dim = config['model']['strides_dim'] #: !!int 1 # assumes strides to be same across the two dimensions \n",
    "        self.kernel_initializer = config['model']['kernel_initializer'] \n",
    "        self.recurrent_initializer = config['model']['recurrent_initializer']\n",
    "        self.padding = config['model']['padding']\n",
    "        self.conv_activation = config['model']['conv_activation']\n",
    "        self.recurrent_activation = config['model']['recurrent_activation']\n",
    "\n",
    "    def compile(self):\n",
    "        # set seed before compiling\n",
    "        tf.random.set_seed(self.seed)\n",
    "\n",
    "        time_steps = self.window_size\n",
    "        _, window, height, width, _ = self.x_iv_train.shape\n",
    "        channels = 1 \n",
    "        # height = len(data_train['moneyness'].unique())\n",
    "        # width = len(data_train['maturity'].unique())\n",
    "        self.model = Sequential()\n",
    "        self.model.add(InputLayer(input_shape=(time_steps, height, width, channels)))\n",
    "        self.model.add(Masking(mask_value=0.0))\n",
    "        # self.model.add(Masking(mask_value=0.0))\n",
    "        # ConvLSTM2D expects 5D input: (batch, time, height, width, channels)\n",
    "\n",
    "        for i in range(self.num_layer-1):\n",
    "            self.model.add(ConvLSTM2D(filters=self.filters, \n",
    "                                      kernel_size=(self.kernel_height, self.kernel_width),\n",
    "                                      strides=(self.strides_dim, self.strides_dim),\n",
    "                                    padding=self.padding, \n",
    "                                    return_sequences=True,\n",
    "                                    kernel_initializer=self.kernel_initializer,\n",
    "                                    recurrent_initializer=self.recurrent_initializer,\n",
    "                                    activation=self.conv_activation,\n",
    "                                    recurrent_activation=self.recurrent_activation\n",
    "                                ))\n",
    "            self.model.add(BatchNormalization())\n",
    "\n",
    "        self.model.add(ConvLSTM2D(filters=self.filters, \n",
    "                                  kernel_size=(self.kernel_height, self.kernel_width),\n",
    "                                  strides=(self.strides_dim, self.strides_dim),\n",
    "                                  padding=self.padding, \n",
    "                                  return_sequences=False,\n",
    "                                  kernel_initializer=self.kernel_initializer,\n",
    "                                  recurrent_initializer=self.recurrent_initializer,\n",
    "                                  activation=self.conv_activation,\n",
    "                                  recurrent_activation=self.recurrent_activation))\n",
    "        self.model.add(BatchNormalization())\n",
    "\n",
    "        # Final 3D convolution to map to the next frame\n",
    "        self.model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=(1, 1),\n",
    "                                        activation='sigmoid', padding='same'))\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate, epsilon=self.epsilon)\n",
    "        self.model.compile(loss=masked_mse, optimizer=self.optimizer)\n",
    "\n",
    "        # Double check the architecture, and the activaiton function\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def fit(self):\n",
    "        self.history = self.model.fit(self.x_iv_train, self.target_train,\n",
    "                validation_data=(self.x_iv_val, self.target_val),\n",
    "                epochs=self.epochs, batch_size=self.batch_size, shuffle=False,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                            patience=self.patience,\n",
    "                                                            mode='min')])\n",
    "        best_epoch = int(np.argmin(self.history.history['val_loss'])) + 1\n",
    "        best_val_loss = self.history.history['val_loss'][best_epoch-1]\n",
    "        train_loss = self.history.history['loss']\n",
    "        val_loss = self.history.history.get('val_loss')\n",
    "        return best_epoch, best_val_loss, train_loss, val_loss\n",
    "    \n",
    "    def fit_test(self, num_epoch):\n",
    "        self.model.fit(self.x_iv_train, self.target_train,\n",
    "                epochs=num_epoch, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def pred(self, x_iv): \n",
    "        pred = self.model.predict(x_iv)\n",
    "        return pred\n",
    "    \n",
    "    def plot_architecture(self, filename='convlstm.png'):\n",
    "        plot_model(self.model, to_file=filename, show_shapes=True, show_layer_names=False,\n",
    "                   dpi=300, rankdir='TB')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a286d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'short_ttm'\n",
    "option_type ='put'\n",
    "smooth=True\n",
    "full_train=False\n",
    "covariate_columns = []\n",
    "h_step = 1\n",
    "temporary_map = 'data/final/binned'\n",
    "window_size = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc98fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iv_train, x_cov_train, target_train, x_iv_val, x_cov_val, \\\n",
    "            target_val, x_iv_test, x_cov_test, target_test, IV_train, IV_val, IV_test = \\\n",
    "                dataloader(run, option_type, smooth, full_train, covariate_columns, window_size, \n",
    "                           h_step, folder_path=temporary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_original = 'config_file.yaml'\n",
    "config = get_config(config_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6073f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvLSTM(x_iv_train, target_train, x_iv_val, target_val, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c799c528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 21, 9, 5, 1)       0         \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, 21, 9, 5, 64)      150016    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 21, 9, 5, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 9, 5, 64)          295168    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 9, 5, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 9, 5, 1)           65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 445,761\n",
      "Trainable params: 445,505\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2f832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_architecture('figures/architectures/convlstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed22039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CovConvLSTM:\n",
    "\n",
    "    def __init__(self, x_iv_train, x_cov_train, y_iv_train, \\\n",
    "                 x_iv_val=None, x_cov_val=None, y_iv_val=None, config=None):\n",
    "        self.read_config(config) # Read the parameters and set the data\n",
    "        self.x_iv_train = x_iv_train\n",
    "        self.x_cov_train = x_cov_train\n",
    "        self.target_train = y_iv_train\n",
    "        self.x_iv_val = x_iv_val\n",
    "        self.x_cov_val = x_cov_val\n",
    "        self.target_val = y_iv_val\n",
    "\n",
    "    def read_config(self, config):\n",
    "       \n",
    "        self.patience = config['training']['patience']\n",
    "        self.epsilon = config['training']['epsilon']\n",
    "        self.batch_size = config['training']['batch_size']\n",
    "        self.epochs = config['training']['epochs']\n",
    "        self.seed = config['training']['seed']\n",
    "        self.learning_rate = config['training']['lr']\n",
    "\n",
    "        self.window_size = config['data']['window_size']\n",
    "        self.run = config['data']['run']\n",
    "        self.covariate_columns = config['data']['covariates']\n",
    "        self.option_type = config['data']['option']\n",
    "        self.smooth = config['data']['smooth']\n",
    "        self.h_step = config['data']['h_step']\n",
    "\n",
    "        self.filters = config['model']['filters'] # 16 32 64 128 filter within the conv2DLSTM layer\n",
    "        self.kernel_height = config['model']['kernel_height']\n",
    "        self.kernel_width = config['model']['kernel_width'] # 1 to 5 (maturity) mxn -> 9x5\n",
    "        self.num_layer = config['model']['num_layer'] # Any positive integer >0\n",
    "        self.strides_dim = config['model']['strides_dim'] #: !!int 1 # assumes strides to be same across the two dimensions \n",
    "        self.kernel_initializer = config['model']['kernel_initializer'] \n",
    "        self.recurrent_initializer = config['model']['recurrent_initializer']\n",
    "        self.padding = config['model']['padding']\n",
    "        self.conv_activation = config['model']['conv_activation']\n",
    "        self.recurrent_activation = config['model']['recurrent_activation']\n",
    "\n",
    "    def compile(self):\n",
    "        # set seed before compiling\n",
    "        tf.random.set_seed(self.seed)\n",
    "\n",
    "        time_steps = self.window_size\n",
    "        _, window, height, width, _ = self.x_iv_train.shape\n",
    "        # height = len(data_train['moneyness'].unique())\n",
    "        # width = len(data_train['maturity'].unique())\n",
    "        num_covariates = len(self.covariate_columns)\n",
    "\n",
    "        # skip seed for now, first check results\n",
    "        \n",
    "        iv_input = Input(shape=(time_steps, height, width, 1), name=\"iv_input\")\n",
    "        x_iv = Masking(mask_value=0.0)(iv_input)\n",
    "\n",
    "        for i in range(self.num_layer-1):\n",
    "            x_iv = ConvLSTM2D(filters=self.filters, \n",
    "                                    kernel_size=(self.kernel_height, self.kernel_width),\n",
    "                                    strides=(self.strides_dim, self.strides_dim),\n",
    "                                    padding=self.padding, \n",
    "                                    return_sequences=True,\n",
    "                                    kernel_initializer=self.kernel_initializer,\n",
    "                                    recurrent_initializer=self.recurrent_initializer,\n",
    "                                    activation=self.conv_activation,\n",
    "                                    recurrent_activation=self.recurrent_activation)(iv_input)\n",
    "            x_iv = BatchNormalization()(x_iv)\n",
    "\n",
    "        x_iv = ConvLSTM2D(filters=self.filters, \n",
    "                                    kernel_size=(self.kernel_height, self.kernel_width),\n",
    "                                    strides=(self.strides_dim, self.strides_dim),\n",
    "                                    padding=self.padding, \n",
    "                                    return_sequences=False,\n",
    "                                    kernel_initializer=self.kernel_initializer,\n",
    "                                    recurrent_initializer=self.recurrent_initializer,\n",
    "                                    activation=self.conv_activation,\n",
    "                                    recurrent_activation=self.recurrent_activation)(x_iv)\n",
    "        x_iv = BatchNormalization()(x_iv)\n",
    "\n",
    "        cov_input = Input(shape=(time_steps, num_covariates), name=\"cov_input\")\n",
    "        # LSTM layer for the covariates\n",
    "        x_cov = LSTM(units=64, return_sequences=False)(cov_input)   # (batch_size, 64)\n",
    "        x_cov = Dense(units=height * width, activation='relu')(x_cov)  \n",
    "        x_cov = Reshape((height, width, 1))(x_cov)               # (batch_size, H, W, 1)\n",
    "\n",
    "        x = Concatenate(axis=-1)([x_iv, x_cov])  # Combine along channel axis -> (H, W, 65)\n",
    "        x = tf.keras.layers.Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        self.model = Model(inputs=[iv_input, cov_input], outputs=x)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate, epsilon=self.epsilon)\n",
    "        self.model.compile(loss=masked_mse, optimizer=optimizer)\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def fit(self):\n",
    "        self.history = self.model.fit([self.x_iv_train, self.x_cov_train], self.target_train,\n",
    "                validation_data=([self.x_iv_val, self.x_cov_val], self.target_val),\n",
    "                epochs=self.epochs, batch_size=self.batch_size, shuffle=False,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                            patience=self.patience,\n",
    "                                                            mode='min')])\n",
    "        best_epoch = int(np.argmin(self.history.history['val_loss'])) + 1\n",
    "        best_val_loss = self.history.history['val_loss'][best_epoch]\n",
    "        train_loss = self.history.history['loss']\n",
    "        val_loss = self.history.history.get('val_loss')\n",
    "        return best_epoch, best_val_loss, train_loss, val_loss\n",
    "    \n",
    "    def fit_test(self, num_epoch):\n",
    "        self.model.fit([self.x_iv_train, self.x_cov_train], self.target_train,\n",
    "                epochs=num_epoch, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def pred(self, x_iv, x_cov): \n",
    "        pred = self.model.predict([x_iv, x_cov])\n",
    "        return pred\n",
    "    \n",
    "    def plot_architecture(self, filename='covconvlstm.png'):\n",
    "        plot_model(self.model, to_file=filename, show_shapes=True, show_layer_names=False,\n",
    "                   dpi=300, rankdir='TB')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09b9f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = 'config_file_covs2.yaml'\n",
    "config = get_config(config_name)\n",
    "\n",
    "covariate_columns = config['data']['covariates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea7f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iv_train, x_cov_train, target_train, x_iv_val, x_cov_val, \\\n",
    "            target_val, x_iv_test, x_cov_test, target_test, IV_train, IV_val, IV_test = \\\n",
    "                dataloader(run, option_type, smooth, full_train, covariate_columns, window_size, \n",
    "                           h_step, folder_path=temporary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8374d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm = CovConvLSTM(x_iv_train, x_cov_train, target_train, x_iv_val, x_cov_val, target_val, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f543a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " iv_input (InputLayer)          [(None, 21, 9, 5, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv_lstm2d_2 (ConvLSTM2D)     (None, 21, 9, 5, 64  199936      ['iv_input[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " cov_input (InputLayer)         [(None, 21, 8)]      0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 21, 9, 5, 64  256        ['conv_lstm2d_2[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           18688       ['cov_input[0][0]']              \n",
      "                                                                                                  \n",
      " conv_lstm2d_3 (ConvLSTM2D)     (None, 9, 5, 64)     393472      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 45)           2925        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 9, 5, 64)    256         ['conv_lstm2d_3[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 9, 5, 1)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 9, 5, 65)     0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 9, 5, 1)      66          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 615,599\n",
      "Trainable params: 615,343\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_lstm.compile()\n",
    "conv_lstm.plot_architecture('figures/architectures/covconvlstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39ce5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Transformer:\n",
    "\n",
    "    def __init__(self, x_iv_train, y_iv_train, \\\n",
    "                 x_iv_val=None, y_iv_val=None, config=None):\n",
    "        self.read_config(config) \n",
    "        self.x_iv_train = x_iv_train\n",
    "        self.target_train = y_iv_train\n",
    "        self.x_iv_val = x_iv_val\n",
    "        self.target_val = y_iv_val\n",
    "\n",
    "    def read_config(self, config):\n",
    "\n",
    "        self.patience = config['training']['patience']\n",
    "        self.epsilon = config['training']['epsilon']\n",
    "        self.batch_size = config['training']['batch_size']\n",
    "        self.epochs = config['training']['epochs']\n",
    "        self.seed = config['training']['seed']\n",
    "        self.learning_rate = config['training']['lr']\n",
    "\n",
    "        self.window_size = config['data']['window_size']\n",
    "        self.run = config['data']['run']\n",
    "        self.covariate_columns = config['data']['covariates']\n",
    "        self.option_type = config['data']['option']\n",
    "        self.smooth = config['data']['smooth']\n",
    "        self.h_step = config['data']['h_step']\n",
    "\n",
    "        # self.filters = config['model']['filters'] # 16 32 64 128 filter within the conv2DLSTM layer\n",
    "        # self.kernel_height = config['model']['kernel_height']\n",
    "        # self.kernel_width = config['model']['kernel_width'] # 1 to 5 (maturity) mxn -> 9x5\n",
    "        # self.num_layer = config['model']['num_layer'] # Any positive integer >0\n",
    "        # self.strides_dim = config['model']['strides_dim'] #: !!int 1 # assumes strides to be same across the two dimensions \n",
    "        # self.kernel_initializer = config['model']['kernel_initializer'] \n",
    "        # self.recurrent_initializer = config['model']['recurrent_initializer']\n",
    "        # self.padding = config['model']['padding']\n",
    "        # self.conv_activation = config['model']['conv_activation']\n",
    "        # self.recurrent_activation = config['model']['recurrent_activation']\n",
    "        self.num_heads = config['model']['num_heads']\n",
    "        self.key_dim = config['model']['key_dim']\n",
    "\n",
    "    def compile(self):\n",
    "        tf.random.set_seed(self.seed)\n",
    "\n",
    "        time_steps = self.window_size\n",
    "        _, window, height, width, _ = self.x_iv_train.shape\n",
    "        channels = 1\n",
    "\n",
    "        inputs = tf.keras.Input(shape=(time_steps, height, width, channels))\n",
    "        x = tf.keras.layers.Reshape((time_steps, height * width))(inputs)  # flatten spatial grid\n",
    "        x = tf.keras.layers.Dense(64)(x)  # project to embedding dim\n",
    "\n",
    "        def create_causal_mask(seq_len):\n",
    "            return np.triu(np.ones((seq_len, seq_len)), k=1)\n",
    "\n",
    "        # When calling the self-attention layer\n",
    "        mask = create_causal_mask(time_steps)  # time_steps is the sequence length\n",
    "\n",
    "        self_attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            key_dim=self.key_dim,\n",
    "            name=\"self_attention\",\n",
    "        )\n",
    "\n",
    "        attention_output, attention_scores = self_attention(\n",
    "            x, x, attention_mask=mask, return_attention_scores=True\n",
    "        )\n",
    "\n",
    "\n",
    "        x = tf.keras.layers.Add()([x, attention_output])\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(height * width)(x)\n",
    "        outputs = tf.keras.layers.Reshape((height, width, 1))(x[:, -1])  # predict for last time step\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=self.learning_rate, epsilon=self.epsilon)\n",
    "        self.model.compile(loss=masked_mse, optimizer=self.optimizer)\n",
    "\n",
    "        print(self.model.summary())\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        self.history = self.model.fit(self.x_iv_train, self.target_train,\n",
    "                validation_data=(self.x_iv_val, self.target_val),\n",
    "                epochs=self.epochs, batch_size=self.batch_size, shuffle=False,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                            patience=self.patience,\n",
    "                                                            mode='min')])\n",
    "        best_epoch = int(np.argmin(self.history.history['val_loss'])) + 1\n",
    "        best_val_loss = self.history.history['val_loss'][best_epoch-1]\n",
    "        train_loss = self.history.history['loss']\n",
    "        val_loss = self.history.history.get('val_loss')\n",
    "        return best_epoch, best_val_loss, train_loss, val_loss\n",
    "    \n",
    "    def fit_test(self, num_epoch):\n",
    "        self.model.fit(self.x_iv_train, self.target_train,\n",
    "                epochs=num_epoch, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "\n",
    "    def get_attention(self):\n",
    "        sample_input = self.x_iv_val[0:1]  #(1, time, height, width, channels)\n",
    "\n",
    "        flattened = tf.reshape(sample_input, (1, sample_input.shape[1], -1))  # (1, time, H*W)\n",
    "\n",
    "        dense = tf.keras.layers.Dense(64)  \n",
    "        embedded = dense(flattened)\n",
    "\n",
    "        # attention layer\n",
    "        attention_layer = self.model.get_layer(\"self_attention\")\n",
    "        attention_output, attn_weights = attention_layer(\n",
    "            embedded, embedded, return_attention_scores=True)\n",
    "        \n",
    "        return attn_weights\n",
    "    \n",
    "    def pred(self, x_iv): \n",
    "        pred = self.model.predict(x_iv)\n",
    "        return pred\n",
    "    \n",
    "    def plot_architecture(self, filename='transformer.png'):\n",
    "        plot_model(self.model, to_file=filename, show_shapes=True, show_layer_names=False,\n",
    "                   dpi=300, rankdir='TB')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47fd6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_original = 'config_file_transformer.yaml'\n",
    "config = get_config(config_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "793d9bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 21, 9, 5, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 21, 45)       0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 21, 64)       2944        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " self_attention (MultiHeadAtten  ((None, 21, 64),    16640       ['dense_1[0][0]',                \n",
      " tion)                           (None, 4, 21, 21))               'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 21, 64)       0           ['dense_1[0][0]',                \n",
      "                                                                  'self_attention[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 21, 64)      128         ['add[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 21, 64)       4160        ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 21, 45)       2925        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 45)          0           ['dense_3[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 9, 5, 1)      0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,797\n",
      "Trainable params: 26,797\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(x_iv_train, target_train, x_iv_val, target_val, config)\n",
    "transformer.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "900d1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.plot_architecture('figures/architectures/transformer.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb318eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovTransformer:\n",
    "\n",
    "    def __init__(self, x_iv_train, x_cov_train, y_iv_train, \\\n",
    "                 x_iv_val=None, x_cov_val=None, y_iv_val=None, config=None):\n",
    "        self.read_config(config) \n",
    "        self.x_iv_train = x_iv_train\n",
    "        self.x_cov_train = x_cov_train\n",
    "        self.target_train = y_iv_train\n",
    "        self.x_iv_val = x_iv_val\n",
    "        self.x_cov_val = x_cov_val\n",
    "        self.target_val = y_iv_val\n",
    "\n",
    "    def read_config(self, config):\n",
    "       \n",
    "        self.patience = config['training']['patience']\n",
    "        self.epsilon = config['training']['epsilon']\n",
    "        self.batch_size = config['training']['batch_size']\n",
    "        self.epochs = config['training']['epochs']\n",
    "        self.seed = config['training']['seed']\n",
    "        self.learning_rate = config['training']['lr']\n",
    "\n",
    "        self.window_size = config['data']['window_size']\n",
    "        self.run = config['data']['run']\n",
    "        self.covariate_columns = config['data']['covariates']\n",
    "        self.option_type = config['data']['option']\n",
    "        self.smooth = config['data']['smooth']\n",
    "        self.h_step = config['data']['h_step']\n",
    "\n",
    "        self.num_heads = config['model']['num_heads']\n",
    "        self.key_dim = config['model']['key_dim']\n",
    "\n",
    "    def compile(self):\n",
    "        tf.random.set_seed(self.seed)\n",
    "\n",
    "        time_steps = self.window_size\n",
    "        _, window, height, width, _ = self.x_iv_train.shape\n",
    "        num_covariates = len(self.covariate_columns)\n",
    "        patch_dim = height * width\n",
    "\n",
    "        iv_input = Input(shape=(time_steps, height, width, 1), name=\"iv_input\")\n",
    "        cov_input = Input(shape=(time_steps, num_covariates), name=\"cov_input\")\n",
    "        \n",
    "        x_iv = tf.reshape(iv_input, [-1, time_steps, patch_dim])  # (B, T, H*W)\n",
    "        x_iv = Dense(64)(x_iv)  # feature space\n",
    "        x_iv = LayerNormalization()(x_iv)\n",
    "\n",
    "        positions = tf.range(start=0, limit=time_steps, delta=1)\n",
    "        pos_encoding = Embedding(input_dim=time_steps, output_dim=64)(positions) \n",
    "        x_iv += pos_encoding  \n",
    "\n",
    "        def create_causal_mask(seq_len):\n",
    "           return np.triu(np.ones((seq_len, seq_len)), k=1)\n",
    "\n",
    "        # # When calling the self-attention layer\n",
    "        mask = create_causal_mask(time_steps)  # time_steps is the sequence length\n",
    "\n",
    "        # self_attention = tf.keras.layers.MultiHeadAttention(\n",
    "        #     num_heads=self.num_heads,\n",
    "        #     key_dim=self.key_dim,\n",
    "        #     name=\"self_attention\",\n",
    "        # )\n",
    "\n",
    "        # attention_output, attention_scores = self_attention(\n",
    "        #     x, x, attention_mask=mask, return_attention_scores=True\n",
    "        # )\n",
    "\n",
    "        #Transformer \n",
    "        attn_output = MultiHeadAttention(num_heads=self.num_heads, \n",
    "                                         key_dim=self.key_dim)(x_iv, x_iv, attention_mask = mask) \n",
    "        x = Add()([x_iv, attn_output])\n",
    "        x = LayerNormalization()(x)\n",
    "        #Feedforward layer\n",
    "        ff = Dense(128, activation='relu')(x)\n",
    "        ff = Dense(64)(ff)\n",
    "        x = Add()([x, ff])\n",
    "        x = LayerNormalization()(x)\n",
    "\n",
    "        x_iv_out = x[:, -1, :]  \n",
    "        x_cov = LSTM(units=64, return_sequences=False)(cov_input)\n",
    "        x_cov = Dense(units=64, activation='relu')(x_cov)\n",
    "\n",
    "        # concat outputs\n",
    "        x = Concatenate()([x_iv_out, x_cov])\n",
    "        x = Dense(units=patch_dim, activation='relu')(x)\n",
    "        x = Reshape((height, width, 1))(x)\n",
    "\n",
    "        x = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        self.model = Model(inputs=[iv_input, cov_input], outputs=x)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate, epsilon=self.epsilon)\n",
    "        self.model.compile(loss=masked_mse, optimizer=optimizer)\n",
    "        print(self.model.summary())\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        self.history = self.model.fit([self.x_iv_train, self.x_cov_train], self.target_train,\n",
    "                validation_data=([self.x_iv_val, self.x_cov_val], self.target_val),\n",
    "                epochs=self.epochs, batch_size=self.batch_size, shuffle=False,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                            patience=self.patience,\n",
    "                                                            mode='min')])\n",
    "        best_epoch = int(np.argmin(self.history.history['val_loss'])) + 1\n",
    "        best_val_loss = self.history.history['val_loss'][best_epoch]\n",
    "        train_loss = self.history.history['loss']\n",
    "        val_loss = self.history.history.get('val_loss')\n",
    "        return best_epoch, best_val_loss, train_loss, val_loss\n",
    "    \n",
    "    def fit_test(self, num_epoch):\n",
    "        self.model.fit([self.x_iv_train, self.x_cov_train], self.target_train,\n",
    "                epochs=num_epoch, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def pred(self, x_iv, x_cov): \n",
    "        pred = self.model.predict([x_iv, x_cov])\n",
    "        return pred\n",
    "    \n",
    "    def plot_architecture(self, filename='covtransformer.png'):\n",
    "        plot_model(self.model, to_file=filename, show_shapes=True, show_layer_names=False,\n",
    "                   dpi=300, rankdir='TB')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f5ab81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " iv_input (InputLayer)          [(None, 21, 9, 5, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 21, 45)       0           ['iv_input[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 21, 64)       2944        ['tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 21, 64)      128         ['dense_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 21, 64)      0           ['layer_normalization_1[0][0]']  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 21, 64)      16640       ['tf.__operators__.add[0][0]',   \n",
      " dAttention)                                                      'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 21, 64)       0           ['tf.__operators__.add[0][0]',   \n",
      "                                                                  'multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 21, 64)      128         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 21, 128)      8320        ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 21, 64)       8256        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 21, 64)       0           ['layer_normalization_2[0][0]',  \n",
      "                                                                  'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " cov_input (InputLayer)         [(None, 21, 8)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 21, 64)      128         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 64)           18688       ['cov_input[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 64)          0           ['layer_normalization_3[0][0]']  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           4160        ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128)          0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 45)           5805        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 9, 5, 1)      0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 9, 5, 1)      2           ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 65,199\n",
      "Trainable params: 65,199\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "config_original = 'config_file_covtransformer.yaml'\n",
    "config = get_config(config_original)\n",
    "\n",
    "\n",
    "transformer = CovTransformer(x_iv_train, x_cov_train, target_train, x_iv_val, x_cov_val, target_val, config)\n",
    "transformer.compile()\n",
    "transformer.plot_architecture(\"figures/architectures/covtransformer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d871eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
