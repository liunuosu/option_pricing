{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390adc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from utils import get_config, print_config, get_results, write_results\n",
    "from utils.dataloader import dataloader, drop_settlement_dup, bin_avg, load_data\n",
    "from utils.loss import plot_loss\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "from model.ahbs import AHBS\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01e94bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_type = 'call'\n",
    "run = 'short_ttm'\n",
    "smooth = True\n",
    "folder_path = 'data/final/binned/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "120a34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, data_test, _ = load_data(run, option_type ,[],False) # full train True is bugged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70c953ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(run, filename, folder_path, raw, covar_df, smooth=False):\n",
    "\n",
    "    # check if specific file exists. If so, just load them. if not, then compute the whole thing\n",
    "    if os.path.isfile(filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    else:\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        # Make train data\n",
    "        df = drop_settlement_dup(raw)\n",
    "\n",
    "        if run =='long_ttm':\n",
    "            bins = [0, 21, 63, 126, 189, 252]\n",
    "            labels = [1, 2, 3, 4, 5] # bin the maturities if it is a long term ttm\n",
    "            df['maturity'] = pd.cut(df['maturity'], bins=bins, labels=labels, include_lowest=True, right=True).astype('Int64') \n",
    "            df = df.dropna(subset=['maturity'])\n",
    "        \n",
    "        moneyness_grid = np.arange(0.80, 1.21, 0.05)\n",
    "        data = bin_avg(df, moneyness_grid, train=smooth)\n",
    "        data.to_csv(filename)\n",
    "    \n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    if covar_df is not None:\n",
    "        data = pd.merge(data, covar_df, on='date', how='left')\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data\n",
    "\n",
    "train_name = f\"data/final/binned/train_{run}_{option_type}_{smooth}.csv\"\n",
    "val_name = f\"data/final/binned/val_{run}_{option_type}.csv\"\n",
    "test_name = f\"data/final/binned/test_{run}_{option_type}.csv\"\n",
    "\n",
    "data_train = retrieve_data(run, train_name,  folder_path, data_train, None, smooth)\n",
    "data_val = retrieve_data(run, val_name, folder_path, data_val, None)\n",
    "data_test = retrieve_data(run, test_name, folder_path, data_test, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f500092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  maturity  moneyness  impl_volatility\n",
      "4    2021-12-07         1       1.00         0.148244\n",
      "12   2021-12-07         3       0.95         0.146452\n",
      "13   2021-12-07         3       1.00         0.162244\n",
      "14   2021-12-07         3       1.05         0.219659\n",
      "21   2021-12-07         4       0.95         0.119259\n",
      "...         ...       ...        ...              ...\n",
      "5116 2022-02-07         5       1.00         0.176799\n",
      "5117 2022-02-07         5       1.05         0.193010\n",
      "5124 2022-02-07         2       0.95         0.194682\n",
      "5125 2022-02-07         2       1.00         0.202714\n",
      "5126 2022-02-07         2       1.05         0.105126\n",
      "\n",
      "[1478 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "850fd618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  maturity  moneyness  impl_volatility\n",
      "4    2021-12-07         1       1.00         0.148244\n",
      "12   2021-12-07         3       0.95         0.146452\n",
      "13   2021-12-07         3       1.00         0.162244\n",
      "14   2021-12-07         3       1.05         0.219659\n",
      "21   2021-12-07         4       0.95         0.119259\n",
      "...         ...       ...        ...              ...\n",
      "5116 2022-02-07         5       1.00         0.176799\n",
      "5117 2022-02-07         5       1.05         0.193010\n",
      "5124 2022-02-07         2       0.95         0.194682\n",
      "5125 2022-02-07         2       1.00         0.202714\n",
      "5126 2022-02-07         2       1.05         0.105126\n",
      "\n",
      "[1478 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac066067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/final/smoothed/data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6500d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0        date               symbol  ... midpoint  year IV_smooth\n",
      "0                0  2012-01-03  SPXW 120106C1200000  ...    77.25  2012  0.356446\n",
      "1                1  2012-01-03  SPXW 120106C1210000  ...    67.40  2012  0.333749\n",
      "2                2  2012-01-03  SPXW 120106C1220000  ...    57.45  2012  0.296131\n",
      "3                3  2012-01-03  SPXW 120106C1230000  ...    47.65  2012  0.268058\n",
      "4                4  2012-01-03  SPXW 120106C1235000  ...    42.75  2012  0.251624\n",
      "...            ...         ...                  ...  ...      ...   ...       ...\n",
      "579882      579882  2021-12-06  SPXW 211213C4830000  ...     0.20  2021  0.144974\n",
      "579883      579883  2021-12-06  SPXW 211213C4835000  ...     0.15  2021  0.146664\n",
      "579884      579884  2021-12-06  SPXW 211213C4840000  ...     0.15  2021  0.148513\n",
      "579885      579885  2021-12-06  SPXW 211213C4845000  ...     0.15  2021  0.150522\n",
      "579886      579886  2021-12-06  SPXW 211213C4850000  ...     0.15  2021  0.152694\n",
      "\n",
      "[223649 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['cp_flag']=='C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b53ba30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0        date               symbol  ... midpoint  year IV_smooth\n",
      "23              23  2012-01-03  SPXW 120106P1195000  ...    0.150  2012  0.323585\n",
      "24              24  2012-01-03  SPXW 120106P1200000  ...    0.175  2012  0.312246\n",
      "25              25  2012-01-03  SPXW 120106P1205000  ...    0.225  2012  0.304897\n",
      "26              26  2012-01-03  SPXW 120106P1210000  ...    0.275  2012  0.295065\n",
      "27              27  2012-01-03  SPXW 120106P1215000  ...    0.275  2012  0.275789\n",
      "...            ...         ...                  ...  ...      ...   ...       ...\n",
      "580063      580063  2021-12-06  SPXW 211213P4760000  ...  170.450  2021  0.133277\n",
      "580064      580064  2021-12-06  SPXW 211213P4770000  ...  180.100  2021  0.129533\n",
      "580065      580065  2021-12-06  SPXW 211213P4775000  ...  185.150  2021  0.127670\n",
      "580066      580066  2021-12-06  SPXW 211213P4820000  ...  229.350  2021  0.111192\n",
      "580067      580067  2021-12-06  SPXW 211213P4840000  ...  249.550  2021  0.104033\n",
      "\n",
      "[356419 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['cp_flag']=='P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31ae44df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  maturity  moneyness  impl_volatility\n",
      "3      2012-01-03         3       0.95         0.184449\n",
      "4      2012-01-03         3       1.00         0.185676\n",
      "5      2012-01-03         3       1.05         0.282994\n",
      "47     2020-06-24         3       0.90         0.246565\n",
      "48     2020-06-24         3       0.95         0.245337\n",
      "...           ...       ...        ...              ...\n",
      "108184 2015-09-14         3       1.00         0.296425\n",
      "108185 2015-09-14         3       1.05         0.360390\n",
      "108264 2015-09-11         4       0.95         0.179961\n",
      "108265 2015-09-11         4       1.00         0.217244\n",
      "108266 2015-09-11         4       1.05         0.232054\n",
      "\n",
      "[16923 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe53a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHBS accepts maturity in years, not in days\n",
    "\n",
    "data_train['maturity'] = data_train['maturity'] / 252\n",
    "data_val['maturity'] = data_val['maturity'] / 252\n",
    "data_test['maturity'] = data_test['maturity'] / 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed519f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHBS is rolling, and we don't need the entire train sample to make a prediction\n",
    "# it just trains on the IVS of one particular day\n",
    "\n",
    "last_date = data_val['date'].max()\n",
    "last_ivs= data_val[data_val['date']==last_date].copy()\n",
    "data_test = pd.concat([last_ivs, data_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "610f37b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  maturity  moneyness  impl_volatility\n",
      "0    2022-05-19  0.003968       0.95         0.370043\n",
      "1    2022-05-19  0.003968       1.00         0.364060\n",
      "2    2022-05-19  0.003968       1.05         0.546334\n",
      "3    2022-05-19  0.003968       1.10         0.885447\n",
      "4    2022-05-19  0.011905       0.90         0.282979\n",
      "...         ...       ...        ...              ...\n",
      "3438 2022-09-01  0.015873       1.00         0.191120\n",
      "3439 2022-09-01  0.015873       1.05         0.194892\n",
      "3440 2022-09-01  0.019841       0.95         0.192258\n",
      "3441 2022-09-01  0.019841       1.00         0.206488\n",
      "3442 2022-09-01  0.019841       1.05         0.215623\n",
      "\n",
      "[3443 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_test) # run this through the abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86c335e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      moneyness  maturity       date   iv_pred  iv_pred_5  iv_pred_10\n",
      "0          0.85  0.003968 2022-05-19  0.401434   0.401434    0.401434\n",
      "1          0.90  0.003968 2022-05-19  0.354119   0.354119    0.354119\n",
      "2          0.95  0.003968 2022-05-19  0.362815   0.362815    0.362815\n",
      "3          1.00  0.003968 2022-05-19  0.427519   0.427519    0.427519\n",
      "4          1.05  0.003968 2022-05-19  0.548233   0.548233    0.548233\n",
      "...         ...       ...        ...       ...        ...         ...\n",
      "7795       1.00  0.019841 2023-02-28  0.143445   0.143445    0.143445\n",
      "7796       1.05  0.019841 2023-02-28  0.232196   0.232196    0.232196\n",
      "7797       1.10  0.019841 2023-02-28  0.475976   0.475976    0.475976\n",
      "7798       1.15  0.019841 2023-02-28  0.874784   0.874784    0.874784\n",
      "7799       1.20  0.019841 2023-02-28  1.428620   1.428620    1.428620\n",
      "\n",
      "[7800 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "# Build full (moneyness, maturity) grid\n",
    "all_m = sorted(data_test['moneyness'].unique())\n",
    "all_t = sorted(data_test['maturity'].unique())\n",
    "full_grid = pd.DataFrame([(m, t) for t in all_t for m in all_m], columns=['moneyness', 'maturity'])\n",
    "\n",
    "# Iterate through each date\n",
    "for date, group in data_test.groupby('date'):\n",
    "    group = group.sort_values(['maturity', 'moneyness'])\n",
    "\n",
    "    # Fit on available points\n",
    "    m = group['moneyness'].values\n",
    "    t = group['maturity'].values   # convert to years\n",
    "    iv = group['impl_volatility'].values\n",
    "\n",
    "\n",
    "    X_train = np.column_stack([\n",
    "        np.ones_like(m),\n",
    "        m,\n",
    "        m**2,\n",
    "        t,\n",
    "        t**2,\n",
    "        m * t\n",
    "    ])\n",
    "\n",
    "    model = LinearRegression().fit(X_train, iv)\n",
    "\n",
    "    # Predict on full grid\n",
    "    m_full = full_grid['moneyness'].values\n",
    "    t_full = full_grid['maturity'].values \n",
    "\n",
    "    X_full = np.column_stack([\n",
    "        np.ones_like(m_full),\n",
    "        m_full,\n",
    "        m_full**2,\n",
    "        t_full,\n",
    "        t_full**2,\n",
    "        m_full * t_full\n",
    "    ])\n",
    "\n",
    "    iv_pred = model.predict(X_full)\n",
    "    # 1 step, now 4 extra steps\n",
    "    iv_pred_5 = iv_pred.copy()\n",
    "    for i in range(4):\n",
    "        model_5 = LinearRegression().fit(X_full, iv_pred_5)\n",
    "        iv_pred_5 = model_5.predict(X_full)\n",
    "\n",
    "    iv_pred_10 = iv_pred_5.copy()\n",
    "    for i in range(5):\n",
    "        model_10 = LinearRegression().fit(X_full, iv_pred_10)\n",
    "        iv_pred_10 = model_10.predict(X_full)\n",
    "\n",
    "    result_df = full_grid.copy()\n",
    "    result_df['date'] = date\n",
    "    result_df['iv_pred'] = iv_pred\n",
    "    result_df['iv_pred_5'] = iv_pred_5\n",
    "    result_df['iv_pred_10'] = iv_pred_10\n",
    "\n",
    "    results.append(result_df)\n",
    "\n",
    "# Combine and save\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0865c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got the predictions, now just merge with the orginal data_test to get the metric\n",
    "\n",
    "output_df = pd.merge(final_df, data_test, on=['date', 'moneyness','maturity'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc330a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      moneyness  maturity       date  ...  iv_pred_5  iv_pred_10  impl_volatility\n",
      "0          0.85  0.003968 2022-05-19  ...   0.401434    0.401434              NaN\n",
      "1          0.90  0.003968 2022-05-19  ...   0.354119    0.354119              NaN\n",
      "2          0.95  0.003968 2022-05-19  ...   0.362815    0.362815         0.370043\n",
      "3          1.00  0.003968 2022-05-19  ...   0.427519    0.427519         0.364060\n",
      "4          1.05  0.003968 2022-05-19  ...   0.548233    0.548233         0.546334\n",
      "...         ...       ...        ...  ...        ...         ...              ...\n",
      "7795       1.00  0.019841 2023-02-28  ...   0.143445    0.143445         0.185687\n",
      "7796       1.05  0.019841 2023-02-28  ...   0.232196    0.232196         0.261263\n",
      "7797       1.10  0.019841 2023-02-28  ...   0.475976    0.475976              NaN\n",
      "7798       1.15  0.019841 2023-02-28  ...   0.874784    0.874784              NaN\n",
      "7799       1.20  0.019841 2023-02-28  ...   1.428620    1.428620              NaN\n",
      "\n",
      "[7800 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8e462fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE THING IS SHIFTED\n",
    "output_df['iv_pred_shifted'] = output_df.groupby(['moneyness', 'maturity'])['iv_pred'].shift(1)\n",
    "output_df['iv_pred_shifted_5'] = output_df.groupby(['moneyness', 'maturity'])['iv_pred_5'].shift(5)\n",
    "output_df['iv_pred_shifted_10'] = output_df.groupby(['moneyness', 'maturity'])['iv_pred_10'].shift(10)\n",
    "\n",
    "output_df_1 = output_df.dropna(subset=['impl_volatility', 'iv_pred_shifted'])\n",
    "output_df_5 = output_df.dropna(subset=['impl_volatility', 'iv_pred_shifted_5'])\n",
    "output_df_10 = output_df.dropna(subset=['impl_volatility', 'iv_pred_shifted_10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d24857b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ivrmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e554ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydra\\AppData\\Local\\Temp\\ipykernel_21960\\2686978670.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  rmse_per_date_1 = output_df_1.groupby('date').apply(\n"
     ]
    }
   ],
   "source": [
    "rmse_per_date_1 = output_df_1.groupby('date').apply(\n",
    "    lambda df: calculate_ivrmse(df['impl_volatility'].values, df['iv_pred_shifted'].values)\n",
    ").reset_index(name='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bad3e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydra\\AppData\\Local\\Temp\\ipykernel_21960\\1981047214.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  rmse_per_date_5 = output_df_5.groupby('date').apply(\n"
     ]
    }
   ],
   "source": [
    "rmse_per_date_5 = output_df_5.groupby('date').apply(\n",
    "    lambda df: calculate_ivrmse(df['impl_volatility'].values, df['iv_pred_shifted_5'].values)\n",
    ").reset_index(name='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dee54fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydra\\AppData\\Local\\Temp\\ipykernel_21960\\1886273846.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  rmse_per_date_10 = output_df_10.groupby('date').apply(\n"
     ]
    }
   ],
   "source": [
    "rmse_per_date_10 = output_df_10.groupby('date').apply(\n",
    "    lambda df: calculate_ivrmse(df['impl_volatility'].values, df['iv_pred_shifted_10'].values)\n",
    ").reset_index(name='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a88efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_per_date_1.to_csv(f'AHBS_rmse_1_{option_type}.csv')\n",
    "rmse_per_date_5.to_csv(f'AHBS_rmse_5.{option_type}.csv')\n",
    "rmse_per_date_10.to_csv(f'AHBS_rmse_10_{option_type}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "046f8619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15983521426281852\n",
      "0.15033366091456868\n",
      "0.15904768599978736\n"
     ]
    }
   ],
   "source": [
    "print(np.average(rmse_per_date_1['rmse']))\n",
    "print(np.average(rmse_per_date_5['rmse']))\n",
    "print(np.average(rmse_per_date_10['rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d09e4f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12704082497395508\n",
      "0.24810232058203185\n",
      "0.22694430728749126\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(output_df_1['impl_volatility'].values, output_df_1['iv_pred_shifted'].values))\n",
    "print(r2_score(output_df_5['impl_volatility'].values, output_df_5['iv_pred_shifted_5'].values))\n",
    "print(r2_score(output_df_10['impl_volatility'].values, output_df_10['iv_pred_shifted_10'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57884ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
