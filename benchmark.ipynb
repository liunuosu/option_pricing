{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "390adc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from utils import get_config, print_config, get_results, write_results\n",
    "from utils.dataloader import dataloader, drop_settlement_dup, bin_avg, load_data\n",
    "from utils.loss import plot_loss\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01e94bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_type = 'call'\n",
    "run = 'short_ttm'\n",
    "smooth = True\n",
    "folder_path = 'data/final/binned/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "120a34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, data_test, _ = load_data(run, option_type ,[],False) # full train True is bugged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70c953ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(run, filename, folder_path, raw, covar_df, smooth=False):\n",
    "\n",
    "    # check if specific file exists. If so, just load them. if not, then compute the whole thing\n",
    "    if os.path.isfile(filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    else:\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        # Make train data\n",
    "        df = drop_settlement_dup(raw)\n",
    "\n",
    "        if run =='long_ttm':\n",
    "            bins = [0, 21, 63, 126, 189, 252]\n",
    "            labels = [1, 2, 3, 4, 5] # bin the maturities if it is a long term ttm\n",
    "            df['maturity'] = pd.cut(df['maturity'], bins=bins, labels=labels, include_lowest=True, right=True).astype('Int64') \n",
    "            df = df.dropna(subset=['maturity'])\n",
    "        \n",
    "        moneyness_grid = np.arange(0.80, 1.21, 0.05)\n",
    "        data = bin_avg(df, moneyness_grid, train=smooth)\n",
    "        data.to_csv(filename)\n",
    "    \n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    if covar_df is not None:\n",
    "        data = pd.merge(data, covar_df, on='date', how='left')\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data\n",
    "\n",
    "train_name = f\"data/final/binned/train_{run}_{option_type}_{smooth}.csv\"\n",
    "val_name = f\"data/final/binned/val_{run}_{option_type}.csv\"\n",
    "test_name = f\"data/final/binned/test_{run}_{option_type}.csv\"\n",
    "\n",
    "data_train = retrieve_data(run, train_name,  folder_path, data_train, None, smooth)\n",
    "data_val = retrieve_data(run, val_name, folder_path, data_val, None)\n",
    "data_test = retrieve_data(run, test_name, folder_path, data_test, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac066067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= pd.read_csv('data/final/smoothed/data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe53a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHBS accepts maturity in years, not in days\n",
    "\n",
    "data_train['maturity'] = data_train['maturity'] / 252\n",
    "data_val['maturity'] = data_val['maturity'] / 252\n",
    "data_test['maturity'] = data_test['maturity'] / 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed519f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHBS is rolling, and we don't need the entire train sample to make a prediction\n",
    "# it just trains on the IVS of one particular day\n",
    "\n",
    "last_date = data_val['date'].max()\n",
    "last_ivs= data_val[data_val['date']==last_date].copy()\n",
    "data_test = pd.concat([last_ivs, data_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "610f37b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0       date  maturity  moneyness  impl_volatility\n",
      "0           1308 2022-05-19  0.003968       0.95         0.370043\n",
      "1           1309 2022-05-19  0.003968       1.00         0.364060\n",
      "2           1310 2022-05-19  0.003968       1.05         0.546334\n",
      "3           1311 2022-05-19  0.003968       1.10         0.885447\n",
      "4           1316 2022-05-19  0.011905       0.90         0.282979\n",
      "...          ...        ...       ...        ...              ...\n",
      "3438        8707 2022-09-01  0.015873       1.00         0.191120\n",
      "3439        8708 2022-09-01  0.015873       1.05         0.194892\n",
      "3440        8724 2022-09-01  0.019841       0.95         0.192258\n",
      "3441        8725 2022-09-01  0.019841       1.00         0.206488\n",
      "3442        8726 2022-09-01  0.019841       1.05         0.215623\n",
      "\n",
      "[3443 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_test) # run this through the abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "86c335e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      moneyness  maturity       date   iv_pred  iv_pred_5  iv_pred_10  \\\n",
      "0          0.85  0.003968 2022-05-19  0.401434   0.401434    0.401434   \n",
      "1          0.90  0.003968 2022-05-19  0.354119   0.354119    0.354119   \n",
      "2          0.95  0.003968 2022-05-19  0.362815   0.362815    0.362815   \n",
      "3          1.00  0.003968 2022-05-19  0.427519   0.427519    0.427519   \n",
      "4          1.05  0.003968 2022-05-19  0.548233   0.548233    0.548233   \n",
      "...         ...       ...        ...       ...        ...         ...   \n",
      "7795       1.00  0.019841 2023-02-28  0.143445   0.143445    0.143445   \n",
      "7796       1.05  0.019841 2023-02-28  0.232196   0.232196    0.232196   \n",
      "7797       1.10  0.019841 2023-02-28  0.475976   0.475976    0.475976   \n",
      "7798       1.15  0.019841 2023-02-28  0.874784   0.874784    0.874784   \n",
      "7799       1.20  0.019841 2023-02-28  1.428620   1.428620    1.428620   \n",
      "\n",
      "      iv_pred_21  \n",
      "0       0.401434  \n",
      "1       0.354119  \n",
      "2       0.362815  \n",
      "3       0.427519  \n",
      "4       0.548233  \n",
      "...          ...  \n",
      "7795    0.143445  \n",
      "7796    0.232196  \n",
      "7797    0.475976  \n",
      "7798    0.874784  \n",
      "7799    1.428620  \n",
      "\n",
      "[7800 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "# Build full (moneyness, maturity) grid\n",
    "all_m = sorted(data_test['moneyness'].unique())\n",
    "all_t = sorted(data_test['maturity'].unique())\n",
    "full_grid = pd.DataFrame([(m, t) for t in all_t for m in all_m], columns=['moneyness', 'maturity'])\n",
    "\n",
    "# Iterate through each date\n",
    "for date, group in data_test.groupby('date'):\n",
    "    group = group.sort_values(['maturity', 'moneyness'])\n",
    "\n",
    "    # Fit on available points\n",
    "    m = group['moneyness'].values\n",
    "    t = group['maturity'].values   # convert to years\n",
    "    iv = group['impl_volatility'].values\n",
    "\n",
    "\n",
    "    X_train = np.column_stack([\n",
    "        np.ones_like(m),\n",
    "        m,\n",
    "        m**2,\n",
    "        t,\n",
    "        t**2,\n",
    "        m * t\n",
    "    ])\n",
    "\n",
    "    model = LinearRegression().fit(X_train, iv)\n",
    "\n",
    "    # Predict on full grid\n",
    "    m_full = full_grid['moneyness'].values\n",
    "    t_full = full_grid['maturity'].values \n",
    "\n",
    "    X_full = np.column_stack([\n",
    "        np.ones_like(m_full),\n",
    "        m_full,\n",
    "        m_full**2,\n",
    "        t_full,\n",
    "        t_full**2,\n",
    "        m_full * t_full\n",
    "    ])\n",
    "\n",
    "    iv_pred = model.predict(X_full)\n",
    "    # 1 step, now 4 extra steps\n",
    "    iv_pred_5 = iv_pred.copy()\n",
    "    for i in range(4):\n",
    "        model_5 = LinearRegression().fit(X_full, iv_pred_5)\n",
    "        iv_pred_5 = model_5.predict(X_full)\n",
    "\n",
    "    iv_pred_10 = iv_pred_5.copy()\n",
    "    for i in range(5):\n",
    "        model_10 = LinearRegression().fit(X_full, iv_pred_10)\n",
    "        iv_pred_10 = model_10.predict(X_full)\n",
    "    \n",
    "    iv_pred_21 = iv_pred_10.copy()\n",
    "    for i in range(11):\n",
    "        model_21 = LinearRegression().fit(X_full, iv_pred_21)\n",
    "        iv_pred_21 = model_21.predict(X_full)\n",
    "\n",
    "    result_df = full_grid.copy()\n",
    "    result_df['date'] = date\n",
    "    result_df['iv_pred'] = iv_pred\n",
    "    result_df['iv_pred_5'] = iv_pred_5\n",
    "    result_df['iv_pred_10'] = iv_pred_10\n",
    "    result_df['iv_pred_21'] = iv_pred_21\n",
    "\n",
    "    results.append(result_df)\n",
    "\n",
    "# Combine and save\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0865c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got the predictions, now just merge with the orginal data_test to get the metric\n",
    "\n",
    "output_df = pd.merge(final_df, data_test, on=['date', 'moneyness','maturity'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e8e462fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE THING IS SHIFTED\n",
    "output_df['iv_pred_shifted'] = output_df.groupby(['moneyness', 'maturity'])['iv_pred'].shift(1)\n",
    "output_df['iv_pred_shifted_5'] = output_df.groupby(['moneyness', 'maturity'])['iv_pred_5'].shift(5)\n",
    "output_df['iv_pred_shifted_10'] = output_df.groupby(['moneyness', 'maturity'])['iv_pred_10'].shift(10)\n",
    "output_df['iv_pred_shifted_21'] = output_df.groupby(['moneyness', 'maturity'])['iv_pred_21'].shift(21)\n",
    "\n",
    "\n",
    "output_df_1 = output_df.dropna(subset=['impl_volatility', 'iv_pred_shifted'])\n",
    "output_df_5 = output_df.dropna(subset=['impl_volatility', 'iv_pred_shifted_5'])\n",
    "output_df_10 = output_df.dropna(subset=['impl_volatility', 'iv_pred_shifted_10'])\n",
    "output_df_21 = output_df.dropna(subset=['impl_volatility', 'iv_pred_shifted_21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d24857b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ivrmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e554ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydra\\AppData\\Local\\Temp\\ipykernel_25592\\2686978670.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  rmse_per_date_1 = output_df_1.groupby('date').apply(\n"
     ]
    }
   ],
   "source": [
    "rmse_per_date_1 = output_df_1.groupby('date').apply(\n",
    "    lambda df: calculate_ivrmse(df['impl_volatility'].values, df['iv_pred_shifted'].values)\n",
    ").reset_index(name='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bad3e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydra\\AppData\\Local\\Temp\\ipykernel_25592\\1981047214.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  rmse_per_date_5 = output_df_5.groupby('date').apply(\n"
     ]
    }
   ],
   "source": [
    "rmse_per_date_5 = output_df_5.groupby('date').apply(\n",
    "    lambda df: calculate_ivrmse(df['impl_volatility'].values, df['iv_pred_shifted_5'].values)\n",
    ").reset_index(name='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dee54fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydra\\AppData\\Local\\Temp\\ipykernel_25592\\1886273846.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  rmse_per_date_10 = output_df_10.groupby('date').apply(\n"
     ]
    }
   ],
   "source": [
    "rmse_per_date_10 = output_df_10.groupby('date').apply(\n",
    "    lambda df: calculate_ivrmse(df['impl_volatility'].values, df['iv_pred_shifted_10'].values)\n",
    ").reset_index(name='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "416c3518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydra\\AppData\\Local\\Temp\\ipykernel_25592\\2276956129.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  rmse_per_date_21 = output_df_21.groupby('date').apply(\n"
     ]
    }
   ],
   "source": [
    "rmse_per_date_21 = output_df_21.groupby('date').apply(\n",
    "    lambda df: calculate_ivrmse(df['impl_volatility'].values, df['iv_pred_shifted_21'].values)\n",
    ").reset_index(name='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a88efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_per_date_1.to_csv(f'AHBS_rmse_1_{option_type}.csv')\n",
    "rmse_per_date_5.to_csv(f'AHBS_rmse_5.{option_type}.csv')\n",
    "rmse_per_date_10.to_csv(f'AHBS_rmse_10_{option_type}.csv')\n",
    "rmse_per_date_21.to_csv(f'AHBS_rmse_21_{option_type}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "046f8619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.98\n",
      "15.03\n",
      "15.90\n",
      "17.68\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.average(rmse_per_date_1['rmse'])*100:.2f}\")\n",
    "print(f\"{np.average(rmse_per_date_5['rmse'])*100:.2f}\")\n",
    "print(f\"{np.average(rmse_per_date_10['rmse'])*100:.2f}\")\n",
    "print(f\"{np.average(rmse_per_date_21['rmse'])*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d09e4f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.70\n",
      "24.81\n",
      "22.69\n",
      "8.37\n"
     ]
    }
   ],
   "source": [
    "print(f\"{r2_score(output_df_1['impl_volatility'].values, output_df_1['iv_pred_shifted'].values)*100:.2f}\")\n",
    "print(f\"{r2_score(output_df_5['impl_volatility'].values, output_df_5['iv_pred_shifted_5'].values)*100:.2f}\")\n",
    "print(f\"{r2_score(output_df_10['impl_volatility'].values, output_df_10['iv_pred_shifted_10'].values)*100:.2f}\")\n",
    "print(f\"{r2_score(output_df_21['impl_volatility'].values, output_df_21['iv_pred_shifted_21'].values)*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
