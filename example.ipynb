{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 5, 5, 1)]   0         \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, None, 5, 5, 10)    480       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 5, 5, 10)   40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 5, 5, 10)          840       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 5, 5, 10)         40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 5, 5, 1)           11        \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 5, 5)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,411\n",
      "Trainable params: 1,371\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_model(n_params, \n",
    "                 dropout, \n",
    "                 recurrent_dropout, \n",
    "                 n_convlstm_layers = 2,\n",
    "                 hidden_activation =  tf.keras.activations.tanh, \n",
    "                 optimizer = keras.optimizers.Adam()):\n",
    "\n",
    "    # input layer\n",
    "    input_layer = layers.Input(shape= (None,5,5,1) )\n",
    "    \n",
    "    # lstm layers\n",
    "    lstm = input_layer\n",
    "    for i in range( n_convlstm_layers ):\n",
    "        lstm =  layers.ConvLSTM2D( \n",
    "            kernel_size= (1,1), \n",
    "            filters=n_params, \n",
    "            data_format= 'channels_last', \n",
    "            return_sequences = i<n_convlstm_layers-1,\n",
    "            activation=hidden_activation,\n",
    "            padding = \"same\",\n",
    "            dropout=dropout, \n",
    "            recurrent_dropout=recurrent_dropout\n",
    "        )( lstm )\n",
    "        lstm = layers.BatchNormalization()(lstm)    \n",
    "\n",
    "    output = layers.Conv2D(\n",
    "        filters=1, kernel_size=(1, 1), activation=\"linear\", padding=\"same\"\n",
    "    )( lstm )\n",
    "    output_layer = layers.Reshape((5,5))(output)\n",
    "\n",
    "    # compile\n",
    "    model = models.Model( input_layer, output_layer )\n",
    "    model.compile(\n",
    "        loss= \"MAE\",\n",
    "        optimizer=optimizer, \n",
    "    ) \n",
    "    \n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def train_model(model, \n",
    "                x_train, \n",
    "                y_train,\n",
    "                verbose = True, \n",
    "                save : \"dir\" = False,\n",
    "                training_kwarg_overwrites : \"dict\" = {} ):\n",
    "    \n",
    "    # train until we run out of improvement\n",
    "    callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15),\n",
    "    ]\n",
    "    \n",
    "    # train model\n",
    "    training_kwargs = {\n",
    "        \"x\" : x_train,\n",
    "        \"y\" : y_train, #dataset[\"train\"][\"y_scaled\"],\n",
    "        \"epochs\" : 200,\n",
    "        \"batch_size\" : 64,\n",
    "        \"verbose\" : verbose,\n",
    "        \"validation_split\" : 0.2,\n",
    "        \"callbacks\" : callbacks,\n",
    "    } \n",
    "    training_kwargs.update(training_kwarg_overwrites)\n",
    "    train_hist = model.fit( **training_kwargs )\n",
    "    \n",
    "    \n",
    "    if save:\n",
    "        Path(save).mkdir(parents=True, exist_ok=True) # make a home for the models\n",
    "        train_start, train_end = [ f( dataset[\"dates\"][\"train\"] ) for f in (min,max) ]\n",
    "        model_name = \"-\".join( date.strftime(\"%Y%m%d\") for date in [train_start, train_end] )\n",
    "        model.save( save+model_name )\n",
    "        \n",
    "    return model, train_hist\n",
    "\n",
    "model = create_model(n_params=10,dropout=0.1,recurrent_dropout=0.1,n_convlstm_layers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 97s 51ms/step - loss: 0.1493 - accuracy: 0.9539\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0459 - accuracy: 0.9853\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 87s 46ms/step - loss: 0.0326 - accuracy: 0.9897\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0261 - accuracy: 0.9923\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0189 - accuracy: 0.9941\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 0.0294 - accuracy: 0.9899\n",
      "Test accuracy: 0.9898999929428101\n",
      "313/313 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the images to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape images to have a single channel (grayscale) and to a flat vector\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first image and its predicted label\n",
    "plt.imshow(test_images[0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f'Predicted label: {np.argmax(predictions[0])}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
