{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/final/smoothed/data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_lstm2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_lstm2d_4 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m9,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m145\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,065</span> (39.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,065\u001b[0m (39.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,033</span> (39.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,033\u001b[0m (39.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step\n",
      "Example Input Shape: (2, 10, 64, 64, 1)\n",
      "Example Output Shape: (2, 62, 62, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Conv2D\n",
    "\n",
    "# Define a ConvLSTM2D model\n",
    "model = Sequential([\n",
    "    ConvLSTM2D(\n",
    "        filters=16, kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        input_shape=(10, 64, 64, 1),  # (time_steps, rows, cols, channels)\n",
    "        return_sequences=False\n",
    "    ),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=1, kernel_size=(3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Example input data (batch_size, time_steps, rows, cols, channels)\n",
    "batch_size = 2\n",
    "time_steps = 10\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 1\n",
    "\n",
    "# Generate random input data\n",
    "example_input = np.random.rand(batch_size, time_steps, height, width, channels).astype(np.float32)\n",
    "\n",
    "# Example prediction\n",
    "example_output = model.predict(example_input)\n",
    "\n",
    "print(\"Example Input Shape:\", example_input.shape)\n",
    "print(\"Example Output Shape:\", example_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'date', 'symbol', 'exdate', 'last_date', 'cp_flag',\n",
      "       'strike_price', 'best_bid', 'best_offer', 'volume', 'open_interest',\n",
      "       'impl_volatility', 'delta', 'gamma', 'vega', 'theta', 'optionid',\n",
      "       'am_settlement', 'expiry_indicator', 'maturity', 'Open', 'High', 'Low',\n",
      "       'Close', 'Adj Close', 'Volume', 'moneyness', 'midpoint', 'year',\n",
      "       'IV_smooth', 'moneyness_enc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[0.00441805]\n",
      "    [0.78462243]\n",
      "    [0.60830384]\n",
      "    ...\n",
      "    [0.8264866 ]\n",
      "    [0.27865714]\n",
      "    [0.35727894]]\n",
      "\n",
      "   [[0.55810326]\n",
      "    [0.54457855]\n",
      "    [0.44118223]\n",
      "    ...\n",
      "    [0.9903226 ]\n",
      "    [0.10868084]\n",
      "    [0.25383604]]\n",
      "\n",
      "   [[0.3584498 ]\n",
      "    [0.6987579 ]\n",
      "    [0.38816163]\n",
      "    ...\n",
      "    [0.805965  ]\n",
      "    [0.71614414]\n",
      "    [0.23861682]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.41840658]\n",
      "    [0.32790056]\n",
      "    [0.20211615]\n",
      "    ...\n",
      "    [0.71419924]\n",
      "    [0.9230194 ]\n",
      "    [0.5695349 ]]\n",
      "\n",
      "   [[0.49252936]\n",
      "    [0.07024787]\n",
      "    [0.08945027]\n",
      "    ...\n",
      "    [0.4087067 ]\n",
      "    [0.7235932 ]\n",
      "    [0.2812814 ]]\n",
      "\n",
      "   [[0.84742033]\n",
      "    [0.8141357 ]\n",
      "    [0.5402433 ]\n",
      "    ...\n",
      "    [0.20242812]\n",
      "    [0.13229786]\n",
      "    [0.46143883]]]\n",
      "\n",
      "\n",
      "  [[[0.2166206 ]\n",
      "    [0.02787942]\n",
      "    [0.38738784]\n",
      "    ...\n",
      "    [0.07041775]\n",
      "    [0.69705176]\n",
      "    [0.68910635]]\n",
      "\n",
      "   [[0.22827587]\n",
      "    [0.6235555 ]\n",
      "    [0.21824725]\n",
      "    ...\n",
      "    [0.03085022]\n",
      "    [0.13360499]\n",
      "    [0.7088784 ]]\n",
      "\n",
      "   [[0.80750585]\n",
      "    [0.94527465]\n",
      "    [0.5362307 ]\n",
      "    ...\n",
      "    [0.5998129 ]\n",
      "    [0.5475299 ]\n",
      "    [0.04792598]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.37871206]\n",
      "    [0.86544836]\n",
      "    [0.4899493 ]\n",
      "    ...\n",
      "    [0.8852706 ]\n",
      "    [0.54003   ]\n",
      "    [0.01151049]]\n",
      "\n",
      "   [[0.7751892 ]\n",
      "    [0.27064338]\n",
      "    [0.08114453]\n",
      "    ...\n",
      "    [0.01161942]\n",
      "    [0.26067808]\n",
      "    [0.84510857]]\n",
      "\n",
      "   [[0.3501301 ]\n",
      "    [0.39295858]\n",
      "    [0.8637441 ]\n",
      "    ...\n",
      "    [0.00207872]\n",
      "    [0.9868886 ]\n",
      "    [0.83564776]]]\n",
      "\n",
      "\n",
      "  [[[0.12601106]\n",
      "    [0.90931714]\n",
      "    [0.09548939]\n",
      "    ...\n",
      "    [0.877947  ]\n",
      "    [0.71746534]\n",
      "    [0.9296978 ]]\n",
      "\n",
      "   [[0.61133385]\n",
      "    [0.4400116 ]\n",
      "    [0.43676347]\n",
      "    ...\n",
      "    [0.3308797 ]\n",
      "    [0.4521295 ]\n",
      "    [0.9123299 ]]\n",
      "\n",
      "   [[0.89265144]\n",
      "    [0.8511546 ]\n",
      "    [0.7719133 ]\n",
      "    ...\n",
      "    [0.19474596]\n",
      "    [0.09770638]\n",
      "    [0.12956862]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.50204957]\n",
      "    [0.11044747]\n",
      "    [0.40560988]\n",
      "    ...\n",
      "    [0.33650726]\n",
      "    [0.27714783]\n",
      "    [0.97413373]]\n",
      "\n",
      "   [[0.2316882 ]\n",
      "    [0.28858843]\n",
      "    [0.6706904 ]\n",
      "    ...\n",
      "    [0.13821647]\n",
      "    [0.27368242]\n",
      "    [0.20278673]]\n",
      "\n",
      "   [[0.6926287 ]\n",
      "    [0.95028335]\n",
      "    [0.9233517 ]\n",
      "    ...\n",
      "    [0.20470046]\n",
      "    [0.8333988 ]\n",
      "    [0.68239397]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[0.7952684 ]\n",
      "    [0.03031539]\n",
      "    [0.09347801]\n",
      "    ...\n",
      "    [0.31213364]\n",
      "    [0.9716266 ]\n",
      "    [0.36205977]]\n",
      "\n",
      "   [[0.652348  ]\n",
      "    [0.6655528 ]\n",
      "    [0.6513146 ]\n",
      "    ...\n",
      "    [0.14033599]\n",
      "    [0.6346678 ]\n",
      "    [0.8135149 ]]\n",
      "\n",
      "   [[0.92018414]\n",
      "    [0.8220869 ]\n",
      "    [0.39782298]\n",
      "    ...\n",
      "    [0.96812993]\n",
      "    [0.32299402]\n",
      "    [0.85190177]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.20219427]\n",
      "    [0.2974036 ]\n",
      "    [0.578297  ]\n",
      "    ...\n",
      "    [0.36405855]\n",
      "    [0.54079586]\n",
      "    [0.6989712 ]]\n",
      "\n",
      "   [[0.36994493]\n",
      "    [0.8619578 ]\n",
      "    [0.7540706 ]\n",
      "    ...\n",
      "    [0.99828565]\n",
      "    [0.33910325]\n",
      "    [0.10277628]]\n",
      "\n",
      "   [[0.9216037 ]\n",
      "    [0.2878924 ]\n",
      "    [0.6587584 ]\n",
      "    ...\n",
      "    [0.28526482]\n",
      "    [0.01193561]\n",
      "    [0.75140816]]]\n",
      "\n",
      "\n",
      "  [[[0.85369694]\n",
      "    [0.37104255]\n",
      "    [0.4578531 ]\n",
      "    ...\n",
      "    [0.76916176]\n",
      "    [0.79055667]\n",
      "    [0.90429   ]]\n",
      "\n",
      "   [[0.9745024 ]\n",
      "    [0.34859726]\n",
      "    [0.82561135]\n",
      "    ...\n",
      "    [0.16225076]\n",
      "    [0.10977428]\n",
      "    [0.14850764]]\n",
      "\n",
      "   [[0.95849466]\n",
      "    [0.44172317]\n",
      "    [0.85319203]\n",
      "    ...\n",
      "    [0.37282485]\n",
      "    [0.89390165]\n",
      "    [0.70593405]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.7049839 ]\n",
      "    [0.56103927]\n",
      "    [0.37996596]\n",
      "    ...\n",
      "    [0.02700091]\n",
      "    [0.8082254 ]\n",
      "    [0.9284398 ]]\n",
      "\n",
      "   [[0.8548427 ]\n",
      "    [0.2934373 ]\n",
      "    [0.00607639]\n",
      "    ...\n",
      "    [0.28521815]\n",
      "    [0.16408315]\n",
      "    [0.5372961 ]]\n",
      "\n",
      "   [[0.02977574]\n",
      "    [0.5717612 ]\n",
      "    [0.4776721 ]\n",
      "    ...\n",
      "    [0.8780564 ]\n",
      "    [0.21302055]\n",
      "    [0.5951001 ]]]\n",
      "\n",
      "\n",
      "  [[[0.6416554 ]\n",
      "    [0.00716395]\n",
      "    [0.14860666]\n",
      "    ...\n",
      "    [0.1873347 ]\n",
      "    [0.70233023]\n",
      "    [0.79470325]]\n",
      "\n",
      "   [[0.3681641 ]\n",
      "    [0.14231245]\n",
      "    [0.2686781 ]\n",
      "    ...\n",
      "    [0.616769  ]\n",
      "    [0.02417025]\n",
      "    [0.07602263]]\n",
      "\n",
      "   [[0.7301289 ]\n",
      "    [0.24088986]\n",
      "    [0.04354709]\n",
      "    ...\n",
      "    [0.06602274]\n",
      "    [0.24724525]\n",
      "    [0.13251385]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.32685253]\n",
      "    [0.80151373]\n",
      "    [0.67624056]\n",
      "    ...\n",
      "    [0.03240812]\n",
      "    [0.9544797 ]\n",
      "    [0.40520653]]\n",
      "\n",
      "   [[0.425709  ]\n",
      "    [0.72232294]\n",
      "    [0.7355993 ]\n",
      "    ...\n",
      "    [0.54589784]\n",
      "    [0.89913195]\n",
      "    [0.39861968]]\n",
      "\n",
      "   [[0.85358214]\n",
      "    [0.48820123]\n",
      "    [0.6862605 ]\n",
      "    ...\n",
      "    [0.0881649 ]\n",
      "    [0.28600708]\n",
      "    [0.16702263]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.66359544]\n",
      "    [0.82836574]\n",
      "    [0.07697868]\n",
      "    ...\n",
      "    [0.00663837]\n",
      "    [0.52056247]\n",
      "    [0.47303224]]\n",
      "\n",
      "   [[0.29376057]\n",
      "    [0.25364837]\n",
      "    [0.6909565 ]\n",
      "    ...\n",
      "    [0.44300234]\n",
      "    [0.2578695 ]\n",
      "    [0.588756  ]]\n",
      "\n",
      "   [[0.36034572]\n",
      "    [0.5582287 ]\n",
      "    [0.92411494]\n",
      "    ...\n",
      "    [0.9895295 ]\n",
      "    [0.17240095]\n",
      "    [0.9355843 ]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.1998796 ]\n",
      "    [0.3193359 ]\n",
      "    [0.5042893 ]\n",
      "    ...\n",
      "    [0.5462475 ]\n",
      "    [0.51054984]\n",
      "    [0.37473148]]\n",
      "\n",
      "   [[0.40411842]\n",
      "    [0.89795864]\n",
      "    [0.9864879 ]\n",
      "    ...\n",
      "    [0.16755772]\n",
      "    [0.04162078]\n",
      "    [0.16550985]]\n",
      "\n",
      "   [[0.546824  ]\n",
      "    [0.45624807]\n",
      "    [0.6020061 ]\n",
      "    ...\n",
      "    [0.8781793 ]\n",
      "    [0.12422945]\n",
      "    [0.61861944]]]\n",
      "\n",
      "\n",
      "  [[[0.09044658]\n",
      "    [0.5436355 ]\n",
      "    [0.8755932 ]\n",
      "    ...\n",
      "    [0.6566112 ]\n",
      "    [0.02236806]\n",
      "    [0.6037533 ]]\n",
      "\n",
      "   [[0.7751162 ]\n",
      "    [0.8888778 ]\n",
      "    [0.24975023]\n",
      "    ...\n",
      "    [0.8328901 ]\n",
      "    [0.3143736 ]\n",
      "    [0.4547612 ]]\n",
      "\n",
      "   [[0.02407122]\n",
      "    [0.86671984]\n",
      "    [0.32484558]\n",
      "    ...\n",
      "    [0.97805804]\n",
      "    [0.8477273 ]\n",
      "    [0.729064  ]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.24829881]\n",
      "    [0.7602256 ]\n",
      "    [0.9785698 ]\n",
      "    ...\n",
      "    [0.63014764]\n",
      "    [0.82451355]\n",
      "    [0.75107265]]\n",
      "\n",
      "   [[0.36588484]\n",
      "    [0.7383596 ]\n",
      "    [0.76904774]\n",
      "    ...\n",
      "    [0.01045264]\n",
      "    [0.6199963 ]\n",
      "    [0.9859988 ]]\n",
      "\n",
      "   [[0.59458864]\n",
      "    [0.04052577]\n",
      "    [0.92475396]\n",
      "    ...\n",
      "    [0.6536652 ]\n",
      "    [0.7799627 ]\n",
      "    [0.641332  ]]]\n",
      "\n",
      "\n",
      "  [[[0.5772972 ]\n",
      "    [0.22666514]\n",
      "    [0.8516346 ]\n",
      "    ...\n",
      "    [0.32711384]\n",
      "    [0.15332462]\n",
      "    [0.5585939 ]]\n",
      "\n",
      "   [[0.72544664]\n",
      "    [0.9141028 ]\n",
      "    [0.541635  ]\n",
      "    ...\n",
      "    [0.53957236]\n",
      "    [0.41635615]\n",
      "    [0.34043482]]\n",
      "\n",
      "   [[0.18914051]\n",
      "    [0.72822595]\n",
      "    [0.84978235]\n",
      "    ...\n",
      "    [0.3235984 ]\n",
      "    [0.21902677]\n",
      "    [0.7947764 ]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.37070748]\n",
      "    [0.48850793]\n",
      "    [0.5989672 ]\n",
      "    ...\n",
      "    [0.51753813]\n",
      "    [0.8082479 ]\n",
      "    [0.2586925 ]]\n",
      "\n",
      "   [[0.76862794]\n",
      "    [0.2837619 ]\n",
      "    [0.5830332 ]\n",
      "    ...\n",
      "    [0.4814129 ]\n",
      "    [0.53472155]\n",
      "    [0.14311188]]\n",
      "\n",
      "   [[0.5912248 ]\n",
      "    [0.19874261]\n",
      "    [0.02126076]\n",
      "    ...\n",
      "    [0.6564746 ]\n",
      "    [0.889374  ]\n",
      "    [0.15322062]]]\n",
      "\n",
      "\n",
      "  ...\n",
      "\n",
      "\n",
      "  [[[0.10274741]\n",
      "    [0.8877223 ]\n",
      "    [0.8646272 ]\n",
      "    ...\n",
      "    [0.21607143]\n",
      "    [0.06360836]\n",
      "    [0.42499715]]\n",
      "\n",
      "   [[0.6303864 ]\n",
      "    [0.66132504]\n",
      "    [0.6319245 ]\n",
      "    ...\n",
      "    [0.01404119]\n",
      "    [0.4015029 ]\n",
      "    [0.6589529 ]]\n",
      "\n",
      "   [[0.7656319 ]\n",
      "    [0.26513097]\n",
      "    [0.5595998 ]\n",
      "    ...\n",
      "    [0.11266829]\n",
      "    [0.15435079]\n",
      "    [0.8574028 ]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.75328624]\n",
      "    [0.31395492]\n",
      "    [0.46967378]\n",
      "    ...\n",
      "    [0.42044422]\n",
      "    [0.1892547 ]\n",
      "    [0.18406643]]\n",
      "\n",
      "   [[0.6683981 ]\n",
      "    [0.27268425]\n",
      "    [0.9592841 ]\n",
      "    ...\n",
      "    [0.22740297]\n",
      "    [0.06537645]\n",
      "    [0.33840784]]\n",
      "\n",
      "   [[0.25249803]\n",
      "    [0.70986515]\n",
      "    [0.72443384]\n",
      "    ...\n",
      "    [0.1859668 ]\n",
      "    [0.47197318]\n",
      "    [0.7847189 ]]]\n",
      "\n",
      "\n",
      "  [[[0.9454006 ]\n",
      "    [0.51063293]\n",
      "    [0.8343944 ]\n",
      "    ...\n",
      "    [0.83173186]\n",
      "    [0.58413285]\n",
      "    [0.71197957]]\n",
      "\n",
      "   [[0.5848664 ]\n",
      "    [0.64669836]\n",
      "    [0.28625503]\n",
      "    ...\n",
      "    [0.63182104]\n",
      "    [0.23650977]\n",
      "    [0.72494125]]\n",
      "\n",
      "   [[0.41454834]\n",
      "    [0.5240231 ]\n",
      "    [0.8457682 ]\n",
      "    ...\n",
      "    [0.64671636]\n",
      "    [0.7018817 ]\n",
      "    [0.52498645]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.41401145]\n",
      "    [0.61973196]\n",
      "    [0.8029066 ]\n",
      "    ...\n",
      "    [0.39969018]\n",
      "    [0.15325247]\n",
      "    [0.8902746 ]]\n",
      "\n",
      "   [[0.46664748]\n",
      "    [0.18839896]\n",
      "    [0.2681345 ]\n",
      "    ...\n",
      "    [0.28949025]\n",
      "    [0.3704859 ]\n",
      "    [0.7589397 ]]\n",
      "\n",
      "   [[0.12086938]\n",
      "    [0.26049286]\n",
      "    [0.5813733 ]\n",
      "    ...\n",
      "    [0.5900679 ]\n",
      "    [0.99466985]\n",
      "    [0.01560707]]]\n",
      "\n",
      "\n",
      "  [[[0.05153354]\n",
      "    [0.52094847]\n",
      "    [0.74600625]\n",
      "    ...\n",
      "    [0.9120971 ]\n",
      "    [0.03280586]\n",
      "    [0.4097583 ]]\n",
      "\n",
      "   [[0.11872643]\n",
      "    [0.92973304]\n",
      "    [0.976205  ]\n",
      "    ...\n",
      "    [0.9206251 ]\n",
      "    [0.2344449 ]\n",
      "    [0.88408333]]\n",
      "\n",
      "   [[0.49730986]\n",
      "    [0.87290007]\n",
      "    [0.53007525]\n",
      "    ...\n",
      "    [0.65132076]\n",
      "    [0.13831536]\n",
      "    [0.92546844]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[0.54012203]\n",
      "    [0.24375768]\n",
      "    [0.40744182]\n",
      "    ...\n",
      "    [0.8843392 ]\n",
      "    [0.76000667]\n",
      "    [0.19394773]]\n",
      "\n",
      "   [[0.7600888 ]\n",
      "    [0.24902725]\n",
      "    [0.70466   ]\n",
      "    ...\n",
      "    [0.04093579]\n",
      "    [0.08191721]\n",
      "    [0.83436406]]\n",
      "\n",
      "   [[0.87986094]\n",
      "    [0.9211112 ]\n",
      "    [0.3729425 ]\n",
      "    ...\n",
      "    [0.49453944]\n",
      "    [0.03339344]\n",
      "    [0.9262273 ]]]]]\n"
     ]
    }
   ],
   "source": [
    "print(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.5200112 ]\n",
      "   [0.5142514 ]\n",
      "   [0.50893986]\n",
      "   ...\n",
      "   [0.5070945 ]\n",
      "   [0.50442874]\n",
      "   [0.49356198]]\n",
      "\n",
      "  [[0.5176684 ]\n",
      "   [0.5225671 ]\n",
      "   [0.50890046]\n",
      "   ...\n",
      "   [0.5137171 ]\n",
      "   [0.50533587]\n",
      "   [0.49901468]]\n",
      "\n",
      "  [[0.5080214 ]\n",
      "   [0.5169725 ]\n",
      "   [0.5121117 ]\n",
      "   ...\n",
      "   [0.51041186]\n",
      "   [0.5154468 ]\n",
      "   [0.5011171 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5094288 ]\n",
      "   [0.5166764 ]\n",
      "   [0.5148639 ]\n",
      "   ...\n",
      "   [0.508696  ]\n",
      "   [0.5224623 ]\n",
      "   [0.5026477 ]]\n",
      "\n",
      "  [[0.51704293]\n",
      "   [0.5155296 ]\n",
      "   [0.5167592 ]\n",
      "   ...\n",
      "   [0.517774  ]\n",
      "   [0.51942974]\n",
      "   [0.5036689 ]]\n",
      "\n",
      "  [[0.5191037 ]\n",
      "   [0.51870084]\n",
      "   [0.51647514]\n",
      "   ...\n",
      "   [0.51629984]\n",
      "   [0.5184979 ]\n",
      "   [0.5105654 ]]]\n",
      "\n",
      "\n",
      " [[[0.52510226]\n",
      "   [0.519394  ]\n",
      "   [0.5142109 ]\n",
      "   ...\n",
      "   [0.507844  ]\n",
      "   [0.5052271 ]\n",
      "   [0.49503452]]\n",
      "\n",
      "  [[0.5154486 ]\n",
      "   [0.5162368 ]\n",
      "   [0.512833  ]\n",
      "   ...\n",
      "   [0.5028558 ]\n",
      "   [0.4997356 ]\n",
      "   [0.5020287 ]]\n",
      "\n",
      "  [[0.5162291 ]\n",
      "   [0.5185796 ]\n",
      "   [0.5141234 ]\n",
      "   ...\n",
      "   [0.51888096]\n",
      "   [0.51447403]\n",
      "   [0.50160295]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5226729 ]\n",
      "   [0.5221958 ]\n",
      "   [0.5119756 ]\n",
      "   ...\n",
      "   [0.50975   ]\n",
      "   [0.52095616]\n",
      "   [0.50382614]]\n",
      "\n",
      "  [[0.5167834 ]\n",
      "   [0.51890403]\n",
      "   [0.5242723 ]\n",
      "   ...\n",
      "   [0.5101811 ]\n",
      "   [0.5110514 ]\n",
      "   [0.5073838 ]]\n",
      "\n",
      "  [[0.5105346 ]\n",
      "   [0.52049893]\n",
      "   [0.5182478 ]\n",
      "   ...\n",
      "   [0.5101835 ]\n",
      "   [0.5180855 ]\n",
      "   [0.5120479 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(example_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'date', 'symbol', 'exdate', 'last_date', 'cp_flag',\n",
      "       'strike_price', 'best_bid', 'best_offer', 'volume', 'open_interest',\n",
      "       'impl_volatility', 'delta', 'gamma', 'vega', 'theta', 'optionid',\n",
      "       'am_settlement', 'expiry_indicator', 'maturity', 'Open', 'High', 'Low',\n",
      "       'Close', 'Adj Close', 'Volume', 'moneyness', 'midpoint', 'year',\n",
      "       'IV_smooth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.356446\n",
      "1    0.333749\n",
      "2    0.296131\n",
      "3    0.268058\n",
      "4    0.251624\n",
      "Name: IV_smooth, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data_train['IV_smooth'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45627, 30)\n",
      "(16966, 30)\n"
     ]
    }
   ],
   "source": [
    "# amount that is ITM\n",
    "print(data_train[(data_train['cp_flag']=='C') & (data_train['moneyness']> 1.03)].shape)\n",
    "print(data_train[(data_train['cp_flag']=='P') & (data_train['moneyness']< 0.97)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223649, 30)\n",
      "(356419, 30)\n"
     ]
    }
   ],
   "source": [
    "# small percentage, lets not drop them\n",
    "# quick investigation about the amount of puts and calls\n",
    "\n",
    "print(data_train[data_train['cp_flag']=='C'].shape)\n",
    "print(data_train[data_train['cp_flag']=='P'].shape)\n",
    "# Can can run one too, with both of them.. calls would be hindered more than puts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580068, 30)\n",
      "(578724, 30)\n"
     ]
    }
   ],
   "source": [
    "# Drop the observations outside of the range.. \n",
    "# outliers, sort of?\n",
    "print(data_train.shape)\n",
    "data_train = data_train[data_train['moneyness'] >= 0.8]\n",
    "data_train = data_train[data_train['moneyness'] <= 1.6]\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement the thing, where deep OTM, OTM, ATM, ITM, deep ITM is a thing\n",
    "\n",
    "# we have to discriminate between calls and puts\n",
    "# Coding; deep OTM = 1, OTM =2, ATM =3, ITM = 4, deep ITM=5 \n",
    "\n",
    "\n",
    "data_train.loc[(data_train['cp_flag']=='C') & (data_train['moneyness'] <0.90), 'moneyness_enc'] = 1\n",
    "data_train.loc[(data_train['cp_flag']=='C') & (data_train['moneyness'] >=0.90) & (data_train['moneyness'] < 0.97), 'moneyness_enc'] = 2\n",
    "data_train.loc[(data_train['cp_flag']=='C') & (data_train['moneyness'] >=0.97) & (data_train['moneyness'] < 1.03), 'moneyness_enc'] = 3\n",
    "data_train.loc[(data_train['cp_flag']=='C') & (data_train['moneyness'] >=1.03) & (data_train['moneyness'] < 1.10), 'moneyness_enc'] = 4\n",
    "data_train.loc[(data_train['cp_flag']=='C') & (data_train['moneyness'] >=1.10), 'moneyness_enc'] = 5\n",
    "\n",
    "data_train.loc[(data_train['cp_flag']=='P') & (data_train['moneyness'] <0.90), 'moneyness_enc'] = 5\n",
    "data_train.loc[(data_train['cp_flag']=='P') & (data_train['moneyness'] >=0.90) & (data_train['moneyness'] < 0.97), 'moneyness_enc'] = 4\n",
    "data_train.loc[(data_train['cp_flag']=='P') & (data_train['moneyness'] >=0.97) & (data_train['moneyness'] < 1.03), 'moneyness_enc'] = 3\n",
    "data_train.loc[(data_train['cp_flag']=='P') & (data_train['moneyness'] >=1.03) & (data_train['moneyness'] < 1.10), 'moneyness_enc'] = 2\n",
    "data_train.loc[(data_train['cp_flag']=='P') & (data_train['moneyness'] >=1.10), 'moneyness_enc'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578724, 31)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1079, 30)\n",
      "              date  moneyness cp_flag\n",
      "23246   2014-01-13   0.606400       P\n",
      "37154   2014-12-17   0.670963       P\n",
      "57623   2015-12-16   0.592306       P\n",
      "93629   2016-12-12   0.752320       P\n",
      "93630   2016-12-12   0.644846       P\n",
      "93878   2016-12-13   0.649063       P\n",
      "105939  2017-03-15   0.795087       P\n",
      "147763  2018-01-12   0.796069       P\n",
      "207757  2018-10-16   0.780533       P\n",
      "218237  2018-11-19   0.727224       P\n",
      "219573  2018-11-26   0.786309       P\n",
      "221789  2018-12-04   0.794135       P\n",
      "232709  2019-01-10   0.741897       P\n",
      "234130  2019-01-16   0.792758       P\n",
      "235306  2019-01-23   0.694395       P\n",
      "235555  2019-01-24   0.695350       P\n",
      "236161  2019-01-25   0.701253       P\n",
      "237740  2019-02-01   0.751814       P\n",
      "238419  2019-02-07   0.751681       P\n",
      "239216  2019-02-11   0.752722       P\n",
      "240362  2019-02-15   0.771000       P\n",
      "242139  2019-02-27   0.775661       P\n",
      "244698  2019-03-12   0.697880       P\n",
      "246105  2019-03-19   0.786825       P\n",
      "247572  2019-03-27   0.719326       P\n",
      "262497  2019-06-13   0.760958       P\n",
      "268057  2019-07-11   0.789450       P\n",
      "268823  2019-07-15   0.793237       P\n",
      "274829  2019-08-09   0.788824       P\n",
      "274830  2019-08-09   0.729662       P\n",
      "278430  2019-08-23   0.711778       P\n",
      "278673  2019-08-26   0.738046       P\n",
      "278674  2019-08-26   0.719595       P\n",
      "279096  2019-08-28   0.759984       P\n",
      "279097  2019-08-28   0.740497       P\n",
      "279098  2019-08-28   0.721985       P\n",
      "279416  2019-08-29   0.731145       P\n",
      "280201  2019-09-03   0.785478       P\n",
      "280202  2019-09-03   0.764808       P\n",
      "280669  2019-09-05   0.783158       P\n",
      "281330  2019-09-09   0.783797       P\n",
      "281535  2019-09-10   0.784050       P\n",
      "281536  2019-09-10   0.773868       P\n",
      "282574  2019-09-13   0.716045       P\n",
      "283706  2019-09-18   0.715888       P\n",
      "285911  2019-09-27   0.722388       P\n",
      "285912  2019-09-27   0.705188       P\n",
      "286193  2019-09-27   0.779418       P\n",
      "287224  2019-10-03   0.786657       P\n",
      "287225  2019-10-03   0.765955       P\n",
      "291430  2019-10-23   0.751130       P\n",
      "292941  2019-10-30   0.662341       P\n",
      "293472  2019-11-01   0.766727       P\n",
      "293616  2019-11-04   0.654951       P\n",
      "293617  2019-11-04   0.641306       P\n",
      "293834  2019-11-05   0.654174       P\n",
      "293835  2019-11-05   0.640546       P\n",
      "294120  2019-11-07   0.771295       P\n",
      "294684  2019-11-11   0.791541       P\n",
      "294685  2019-11-11   0.771753       P\n",
      "294917  2019-11-12   0.792780       P\n",
      "294918  2019-11-12   0.772960       P\n",
      "297241  2019-11-26   0.785130       P\n",
      "298846  2019-12-05   0.799341       P\n",
      "298847  2019-12-05   0.779357       P\n",
      "300031  2019-12-10   0.783130       P\n",
      "303134  2019-12-19   0.763183       P\n",
      "307195  2020-01-13   0.782888       P\n",
      "307444  2020-01-14   0.781702       P\n",
      "309593  2020-01-24   0.784636       P\n",
      "314627  2020-02-14   0.786084       P\n",
      "317128  2020-02-25   0.762978       P\n",
      "320376  2020-03-03   0.780096       P\n",
      "320377  2020-03-03   0.770095       P\n",
      "320689  2020-03-03   0.750843       P\n",
      "320959  2020-03-03   0.770095       P\n",
      "324334  2020-03-10   0.686245       P\n",
      "325959  2020-03-12   0.770385       C\n",
      "325960  2020-03-12   0.757447       C\n",
      "326096  2020-03-12   0.796353       P\n",
      "326097  2020-03-12   0.795077       P\n",
      "326098  2020-03-12   0.793805       P\n",
      "326099  2020-03-12   0.791273       P\n",
      "326100  2020-03-12   0.790013       P\n",
      "326101  2020-03-12   0.788757       P\n",
      "326102  2020-03-12   0.787505       P\n",
      "326103  2020-03-12   0.785013       P\n",
      "326104  2020-03-12   0.778851       P\n",
      "326105  2020-03-12   0.777630       P\n",
      "326106  2020-03-12   0.775200       P\n",
      "326107  2020-03-12   0.769191       P\n",
      "326108  2020-03-12   0.765630       P\n",
      "326109  2020-03-12   0.764450       P\n",
      "326110  2020-03-12   0.751709       P\n",
      "326111  2020-03-12   0.748308       P\n",
      "326112  2020-03-12   0.746057       P\n",
      "326113  2020-03-12   0.717985       P\n",
      "326114  2020-03-12   0.714882       P\n",
      "326115  2020-03-12   0.700746       P\n",
      "326116  2020-03-12   0.689067       P\n",
      "326509  2020-03-13   0.799711       P\n",
      "326510  2020-03-13   0.795021       P\n",
      "326511  2020-03-13   0.790385       P\n",
      "326512  2020-03-13   0.616141       P\n",
      "326757  2020-03-13   0.792696       P\n",
      "326758  2020-03-13   0.786943       P\n",
      "326759  2020-03-13   0.777911       P\n",
      "327010  2020-03-13   0.786943       P\n",
      "327011  2020-03-13   0.776797       P\n",
      "327012  2020-03-13   0.722939       P\n",
      "327393  2020-03-13   0.797359       P\n",
      "327394  2020-03-13   0.792696       P\n",
      "327395  2020-03-13   0.791539       P\n",
      "327396  2020-03-13   0.790385       P\n",
      "327397  2020-03-13   0.789234       P\n",
      "327398  2020-03-13   0.788087       P\n",
      "327399  2020-03-13   0.630470       P\n",
      "327540  2020-03-16   0.799373       C\n",
      "327541  2020-03-16   0.798037       C\n",
      "327542  2020-03-16   0.796704       C\n",
      "327543  2020-03-16   0.795377       C\n",
      "327544  2020-03-16   0.794053       C\n",
      "327545  2020-03-16   0.788803       C\n",
      "327546  2020-03-16   0.784911       C\n",
      "327547  2020-03-16   0.782338       C\n",
      "327548  2020-03-16   0.781057       C\n",
      "327549  2020-03-16   0.779781       C\n",
      "327550  2020-03-16   0.775977       C\n",
      "327551  2020-03-16   0.774717       C\n",
      "327552  2020-03-16   0.773462       C\n",
      "327553  2020-03-16   0.769719       C\n",
      "327554  2020-03-16   0.767244       C\n",
      "327555  2020-03-16   0.763562       C\n",
      "327556  2020-03-16   0.761126       C\n",
      "327557  2020-03-16   0.759914       C\n",
      "327558  2020-03-16   0.758706       C\n",
      "327559  2020-03-16   0.757502       C\n",
      "327560  2020-03-16   0.756301       C\n",
      "327561  2020-03-16   0.755104       C\n",
      "327562  2020-03-16   0.752722       C\n",
      "327563  2020-03-16   0.750355       C\n",
      "327564  2020-03-16   0.745666       C\n",
      "327565  2020-03-16   0.739885       C\n",
      "327566  2020-03-16   0.723070       C\n",
      "327767  2020-03-16   0.799373       P\n",
      "327768  2020-03-16   0.798037       P\n",
      "327769  2020-03-16   0.791420       P\n",
      "327770  2020-03-16   0.790109       P\n",
      "327771  2020-03-16   0.787502       P\n",
      "327772  2020-03-16   0.786204       P\n",
      "327773  2020-03-16   0.784911       P\n",
      "327774  2020-03-16   0.783622       P\n",
      "327775  2020-03-16   0.782338       P\n",
      "327776  2020-03-16   0.779781       P\n",
      "327777  2020-03-16   0.775977       P\n",
      "327778  2020-03-16   0.774717       P\n",
      "327779  2020-03-16   0.772210       P\n",
      "327780  2020-03-16   0.769719       P\n",
      "327781  2020-03-16   0.767244       P\n",
      "327782  2020-03-16   0.764785       P\n",
      "327783  2020-03-16   0.763562       P\n",
      "327784  2020-03-16   0.762342       P\n",
      "327785  2020-03-16   0.761126       P\n",
      "327786  2020-03-16   0.759914       P\n",
      "327787  2020-03-16   0.758706       P\n",
      "327788  2020-03-16   0.757502       P\n",
      "327789  2020-03-16   0.755104       P\n",
      "327790  2020-03-16   0.752722       P\n",
      "327791  2020-03-16   0.751537       P\n",
      "327792  2020-03-16   0.746833       P\n",
      "327793  2020-03-16   0.745666       P\n",
      "327794  2020-03-16   0.743343       P\n",
      "327795  2020-03-16   0.742187       P\n",
      "327796  2020-03-16   0.741034       P\n",
      "327797  2020-03-16   0.738740       P\n",
      "327798  2020-03-16   0.737598       P\n",
      "327799  2020-03-16   0.736460       P\n",
      "327800  2020-03-16   0.718714       P\n",
      "327801  2020-03-16   0.717633       P\n",
      "327802  2020-03-16   0.716556       P\n",
      "327803  2020-03-16   0.714410       P\n",
      "327804  2020-03-16   0.713342       P\n",
      "327805  2020-03-16   0.712278       P\n",
      "327806  2020-03-16   0.704913       P\n",
      "327807  2020-03-16   0.703873       P\n",
      "327808  2020-03-16   0.701803       P\n",
      "327809  2020-03-16   0.696680       P\n",
      "328178  2020-03-16   0.799373       C\n",
      "328179  2020-03-16   0.798037       C\n",
      "328180  2020-03-16   0.796704       C\n",
      "328181  2020-03-16   0.795377       C\n",
      "328182  2020-03-16   0.794053       C\n",
      "328183  2020-03-16   0.792734       C\n",
      "328184  2020-03-16   0.791420       C\n",
      "328185  2020-03-16   0.790109       C\n",
      "328186  2020-03-16   0.769719       C\n",
      "328187  2020-03-16   0.757502       C\n",
      "328188  2020-03-16   0.745666       C\n",
      "328189  2020-03-16   0.739885       C\n",
      "328190  2020-03-16   0.738740       C\n",
      "328191  2020-03-16   0.734194       C\n",
      "328192  2020-03-16   0.731942       C\n",
      "328193  2020-03-16   0.723070       C\n",
      "328194  2020-03-16   0.717633       C\n",
      "328389  2020-03-16   0.799373       P\n",
      "328390  2020-03-16   0.798037       P\n",
      "328391  2020-03-16   0.796704       P\n",
      "328392  2020-03-16   0.795377       P\n",
      "328393  2020-03-16   0.787502       P\n",
      "328394  2020-03-16   0.786204       P\n",
      "328395  2020-03-16   0.784911       P\n",
      "328396  2020-03-16   0.783622       P\n",
      "328397  2020-03-16   0.782338       P\n",
      "328398  2020-03-16   0.770963       P\n",
      "328399  2020-03-16   0.769719       P\n",
      "328400  2020-03-16   0.768480       P\n",
      "328401  2020-03-16   0.767244       P\n",
      "328402  2020-03-16   0.764785       P\n",
      "328403  2020-03-16   0.763562       P\n",
      "328404  2020-03-16   0.762342       P\n",
      "328405  2020-03-16   0.759914       P\n",
      "328406  2020-03-16   0.743343       P\n",
      "328407  2020-03-16   0.741034       P\n",
      "328408  2020-03-16   0.739885       P\n",
      "328409  2020-03-16   0.738740       P\n",
      "328410  2020-03-16   0.736460       P\n",
      "328411  2020-03-16   0.734194       P\n",
      "328412  2020-03-16   0.733066       P\n",
      "328413  2020-03-16   0.731942       P\n",
      "328414  2020-03-16   0.730821       P\n",
      "328415  2020-03-16   0.729703       P\n",
      "328416  2020-03-16   0.728589       P\n",
      "328417  2020-03-16   0.727479       P\n",
      "328418  2020-03-16   0.726371       P\n",
      "328419  2020-03-16   0.725267       P\n",
      "328420  2020-03-16   0.724167       P\n",
      "328421  2020-03-16   0.723070       P\n",
      "328422  2020-03-16   0.720885       P\n",
      "328423  2020-03-16   0.719798       P\n",
      "328424  2020-03-16   0.686656       P\n",
      "328542  2020-03-16   0.799373       C\n",
      "328543  2020-03-16   0.798037       C\n",
      "328544  2020-03-16   0.796704       C\n",
      "328545  2020-03-16   0.795377       C\n",
      "328546  2020-03-16   0.794053       C\n",
      "328547  2020-03-16   0.792734       C\n",
      "328548  2020-03-16   0.790109       C\n",
      "328549  2020-03-16   0.788803       C\n",
      "328550  2020-03-16   0.782338       C\n",
      "328649  2020-03-16   0.796704       P\n",
      "328650  2020-03-16   0.795377       P\n",
      "328651  2020-03-16   0.787502       P\n",
      "328652  2020-03-16   0.775977       P\n",
      "328653  2020-03-16   0.772210       P\n",
      "328654  2020-03-16   0.769719       P\n",
      "328655  2020-03-16   0.756301       P\n",
      "328656  2020-03-16   0.750355       P\n",
      "328657  2020-03-16   0.745666       P\n",
      "328658  2020-03-16   0.720885       P\n",
      "328659  2020-03-16   0.719798       P\n",
      "328660  2020-03-16   0.718714       P\n",
      "328661  2020-03-16   0.717633       P\n",
      "328662  2020-03-16   0.716556       P\n",
      "328663  2020-03-16   0.715481       P\n",
      "328664  2020-03-16   0.714410       P\n",
      "328665  2020-03-16   0.712278       P\n",
      "328666  2020-03-16   0.711216       P\n",
      "328667  2020-03-16   0.710158       P\n",
      "328668  2020-03-16   0.709102       P\n",
      "328669  2020-03-16   0.708050       P\n",
      "328670  2020-03-16   0.707001       P\n",
      "328671  2020-03-16   0.705956       P\n",
      "328672  2020-03-16   0.704913       P\n",
      "328673  2020-03-16   0.703873       P\n",
      "328674  2020-03-16   0.702836       P\n",
      "328675  2020-03-16   0.701803       P\n",
      "328676  2020-03-16   0.700772       P\n",
      "328677  2020-03-16   0.699745       P\n",
      "328678  2020-03-16   0.698720       P\n",
      "328679  2020-03-16   0.697699       P\n",
      "328680  2020-03-16   0.696680       P\n",
      "328681  2020-03-16   0.695665       P\n",
      "328682  2020-03-16   0.694652       P\n",
      "328683  2020-03-16   0.693642       P\n",
      "328684  2020-03-16   0.691632       P\n",
      "328685  2020-03-16   0.690631       P\n",
      "328686  2020-03-16   0.687645       P\n",
      "329023  2020-03-17   0.799112       P\n",
      "329024  2020-03-17   0.797852       P\n",
      "329025  2020-03-17   0.796595       P\n",
      "329026  2020-03-17   0.795343       P\n",
      "329027  2020-03-17   0.794094       P\n",
      "329028  2020-03-17   0.792850       P\n",
      "329029  2020-03-17   0.791609       P\n",
      "329030  2020-03-17   0.790372       P\n",
      "329031  2020-03-17   0.789139       P\n",
      "329032  2020-03-17   0.786684       P\n",
      "329033  2020-03-17   0.785463       P\n",
      "329034  2020-03-17   0.784245       P\n",
      "329035  2020-03-17   0.783031       P\n",
      "329036  2020-03-17   0.779411       P\n",
      "329037  2020-03-17   0.778212       P\n",
      "329038  2020-03-17   0.777017       P\n",
      "329039  2020-03-17   0.775825       P\n",
      "329040  2020-03-17   0.773453       P\n",
      "329041  2020-03-17   0.772272       P\n",
      "329042  2020-03-17   0.771094       P\n",
      "329043  2020-03-17   0.769921       P\n",
      "329044  2020-03-17   0.766421       P\n",
      "329045  2020-03-17   0.765262       P\n",
      "329046  2020-03-17   0.761804       P\n",
      "329047  2020-03-17   0.760659       P\n",
      "329048  2020-03-17   0.759516       P\n",
      "329049  2020-03-17   0.754982       P\n",
      "329050  2020-03-17   0.751617       P\n",
      "329051  2020-03-17   0.750501       P\n",
      "329052  2020-03-17   0.749390       P\n",
      "329053  2020-03-17   0.746074       P\n",
      "329054  2020-03-17   0.743879       P\n",
      "329055  2020-03-17   0.741698       P\n",
      "329654  2020-03-17   0.797852       P\n",
      "329655  2020-03-17   0.796595       P\n",
      "329656  2020-03-17   0.794094       P\n",
      "329657  2020-03-17   0.792850       P\n",
      "329658  2020-03-17   0.791609       P\n",
      "329659  2020-03-17   0.790372       P\n",
      "329660  2020-03-17   0.787910       P\n",
      "329661  2020-03-17   0.786684       P\n",
      "329662  2020-03-17   0.785463       P\n",
      "329663  2020-03-17   0.784245       P\n",
      "329664  2020-03-17   0.783031       P\n",
      "329665  2020-03-17   0.780614       P\n",
      "329666  2020-03-17   0.779411       P\n",
      "329667  2020-03-17   0.778212       P\n",
      "329668  2020-03-17   0.775825       P\n",
      "329669  2020-03-17   0.774637       P\n",
      "329670  2020-03-17   0.773453       P\n",
      "329671  2020-03-17   0.772272       P\n",
      "329672  2020-03-17   0.771094       P\n",
      "329673  2020-03-17   0.769921       P\n",
      "329674  2020-03-17   0.768751       P\n",
      "329675  2020-03-17   0.766421       P\n",
      "329676  2020-03-17   0.764106       P\n",
      "329677  2020-03-17   0.762953       P\n",
      "329678  2020-03-17   0.760659       P\n",
      "329679  2020-03-17   0.759516       P\n",
      "329680  2020-03-17   0.758378       P\n",
      "329681  2020-03-17   0.756111       P\n",
      "329682  2020-03-17   0.754982       P\n",
      "329683  2020-03-17   0.753857       P\n",
      "329684  2020-03-17   0.752735       P\n",
      "329685  2020-03-17   0.751617       P\n",
      "329686  2020-03-17   0.750501       P\n",
      "329687  2020-03-17   0.747176       P\n",
      "329688  2020-03-17   0.746074       P\n",
      "329689  2020-03-17   0.743879       P\n",
      "329690  2020-03-17   0.741698       P\n",
      "329691  2020-03-17   0.740612       P\n",
      "329692  2020-03-17   0.738450       P\n",
      "329693  2020-03-17   0.737373       P\n",
      "329694  2020-03-17   0.734163       P\n",
      "329695  2020-03-17   0.730980       P\n",
      "329696  2020-03-17   0.728873       P\n",
      "329697  2020-03-17   0.724696       P\n",
      "329698  2020-03-17   0.702553       P\n",
      "329699  2020-03-17   0.697708       P\n",
      "329831  2020-03-17   0.775825       C\n",
      "329969  2020-03-17   0.797852       P\n",
      "329970  2020-03-17   0.796595       P\n",
      "329971  2020-03-17   0.792850       P\n",
      "329972  2020-03-17   0.790372       P\n",
      "329973  2020-03-17   0.786684       P\n",
      "329974  2020-03-17   0.785463       P\n",
      "329975  2020-03-17   0.780614       P\n",
      "329976  2020-03-17   0.778212       P\n",
      "329977  2020-03-17   0.775825       P\n",
      "329978  2020-03-17   0.774637       P\n",
      "329979  2020-03-17   0.773453       P\n",
      "329980  2020-03-17   0.771094       P\n",
      "329981  2020-03-17   0.766421       P\n",
      "329982  2020-03-17   0.764106       P\n",
      "329983  2020-03-17   0.762953       P\n",
      "329984  2020-03-17   0.759516       P\n",
      "329985  2020-03-17   0.758378       P\n",
      "329986  2020-03-17   0.756111       P\n",
      "329987  2020-03-17   0.754982       P\n",
      "329988  2020-03-17   0.753857       P\n",
      "329989  2020-03-17   0.752735       P\n",
      "329990  2020-03-17   0.751617       P\n",
      "329991  2020-03-17   0.750501       P\n",
      "329992  2020-03-17   0.747176       P\n",
      "329993  2020-03-17   0.746074       P\n",
      "329994  2020-03-17   0.743879       P\n",
      "329995  2020-03-17   0.741698       P\n",
      "329996  2020-03-17   0.740612       P\n",
      "329997  2020-03-17   0.738450       P\n",
      "329998  2020-03-17   0.737373       P\n",
      "329999  2020-03-17   0.734163       P\n",
      "330000  2020-03-17   0.730980       P\n",
      "330001  2020-03-17   0.728873       P\n",
      "330002  2020-03-17   0.724696       P\n",
      "330602  2020-03-18   0.799367       P\n",
      "330603  2020-03-18   0.798037       P\n",
      "330604  2020-03-18   0.796711       P\n",
      "330605  2020-03-18   0.795390       P\n",
      "330606  2020-03-18   0.794073       P\n",
      "330607  2020-03-18   0.792760       P\n",
      "330608  2020-03-18   0.791452       P\n",
      "330609  2020-03-18   0.790148       P\n",
      "330610  2020-03-18   0.788849       P\n",
      "330611  2020-03-18   0.787553       P\n",
      "330612  2020-03-18   0.786262       P\n",
      "330613  2020-03-18   0.783693       P\n",
      "330614  2020-03-18   0.781140       P\n",
      "330615  2020-03-18   0.778604       P\n",
      "330616  2020-03-18   0.774830       P\n",
      "330617  2020-03-18   0.773581       P\n",
      "330618  2020-03-18   0.771093       P\n",
      "330619  2020-03-18   0.769856       P\n",
      "330620  2020-03-18   0.768622       P\n",
      "330621  2020-03-18   0.766166       P\n",
      "330622  2020-03-18   0.762512       P\n",
      "330623  2020-03-18   0.761302       P\n",
      "330624  2020-03-18   0.758892       P\n",
      "330625  2020-03-18   0.757694       P\n",
      "330626  2020-03-18   0.756498       P\n",
      "330627  2020-03-18   0.755307       P\n",
      "330628  2020-03-18   0.752936       P\n",
      "330629  2020-03-18   0.743597       P\n",
      "330630  2020-03-18   0.742446       P\n",
      "330631  2020-03-18   0.741298       P\n",
      "330632  2020-03-18   0.740154       P\n",
      "330633  2020-03-18   0.739014       P\n",
      "330755  2020-03-18   0.799367       C\n",
      "330871  2020-03-18   0.799367       P\n",
      "330872  2020-03-18   0.791452       P\n",
      "330873  2020-03-18   0.788849       P\n",
      "330874  2020-03-18   0.787553       P\n",
      "330875  2020-03-18   0.783693       P\n",
      "330876  2020-03-18   0.782414       P\n",
      "330877  2020-03-18   0.781140       P\n",
      "330878  2020-03-18   0.773581       P\n",
      "330879  2020-03-18   0.766166       P\n",
      "330880  2020-03-18   0.762512       P\n",
      "330881  2020-03-18   0.761302       P\n",
      "330882  2020-03-18   0.760095       P\n",
      "330883  2020-03-18   0.758892       P\n",
      "330884  2020-03-18   0.756498       P\n",
      "330885  2020-03-18   0.755307       P\n",
      "330886  2020-03-18   0.751756       P\n",
      "330887  2020-03-18   0.750579       P\n",
      "330888  2020-03-18   0.742446       P\n",
      "330889  2020-03-18   0.741298       P\n",
      "330890  2020-03-18   0.740154       P\n",
      "330891  2020-03-18   0.737877       P\n",
      "330892  2020-03-18   0.736744       P\n",
      "330893  2020-03-18   0.733364       P\n",
      "330894  2020-03-18   0.732244       P\n",
      "330895  2020-03-18   0.728906       P\n",
      "330896  2020-03-18   0.726697       P\n",
      "330897  2020-03-18   0.724502       P\n",
      "330898  2020-03-18   0.721233       P\n",
      "330899  2020-03-18   0.715851       P\n",
      "330900  2020-03-18   0.714784       P\n",
      "330901  2020-03-18   0.713720       P\n",
      "330902  2020-03-18   0.711602       P\n",
      "330903  2020-03-18   0.709497       P\n",
      "330904  2020-03-18   0.707404       P\n",
      "330905  2020-03-18   0.706362       P\n",
      "330906  2020-03-18   0.705324       P\n",
      "330907  2020-03-18   0.704288       P\n",
      "330908  2020-03-18   0.703255       P\n",
      "330909  2020-03-18   0.702226       P\n",
      "330910  2020-03-18   0.701199       P\n",
      "330911  2020-03-18   0.699155       P\n",
      "330912  2020-03-18   0.698137       P\n",
      "330913  2020-03-18   0.695101       P\n",
      "330914  2020-03-18   0.687135       P\n",
      "330915  2020-03-18   0.680312       P\n",
      "330916  2020-03-18   0.670797       P\n",
      "330917  2020-03-18   0.657014       P\n",
      "330918  2020-03-18   0.631079       P\n",
      "331034  2020-03-18   0.799367       C\n",
      "331035  2020-03-18   0.791452       C\n",
      "331142  2020-03-18   0.799367       P\n",
      "331143  2020-03-18   0.798037       P\n",
      "331144  2020-03-18   0.796711       P\n",
      "331145  2020-03-18   0.794073       P\n",
      "331146  2020-03-18   0.791452       P\n",
      "331147  2020-03-18   0.783693       P\n",
      "331148  2020-03-18   0.774830       P\n",
      "331149  2020-03-18   0.773581       P\n",
      "331150  2020-03-18   0.768622       P\n",
      "331151  2020-03-18   0.761302       P\n",
      "331152  2020-03-18   0.754120       P\n",
      "331153  2020-03-18   0.752936       P\n",
      "331154  2020-03-18   0.749406       P\n",
      "331155  2020-03-18   0.740154       P\n",
      "331156  2020-03-18   0.739014       P\n",
      "331157  2020-03-18   0.737877       P\n",
      "331158  2020-03-18   0.733364       P\n",
      "331159  2020-03-18   0.727800       P\n",
      "331160  2020-03-18   0.677429       P\n",
      "331161  2020-03-18   0.639493       P\n",
      "331162  2020-03-18   0.614897       P\n",
      "331426  2020-03-19   0.799134       P\n",
      "331427  2020-03-19   0.796493       P\n",
      "331428  2020-03-19   0.791261       P\n",
      "331429  2020-03-19   0.787382       P\n",
      "331430  2020-03-19   0.782269       P\n",
      "331431  2020-03-19   0.767322       P\n",
      "331432  2020-03-19   0.760060       P\n",
      "331433  2020-03-19   0.747098       P\n",
      "331434  2020-03-19   0.741351       P\n",
      "331435  2020-03-19   0.726814       P\n",
      "331696  2020-03-19   0.796493       P\n",
      "331697  2020-03-19   0.795178       P\n",
      "331698  2020-03-19   0.792562       P\n",
      "331699  2020-03-19   0.789964       P\n",
      "331700  2020-03-19   0.787382       P\n",
      "331701  2020-03-19   0.786098       P\n",
      "331702  2020-03-19   0.784818       P\n",
      "331703  2020-03-19   0.783541       P\n",
      "331704  2020-03-19   0.778478       P\n",
      "331705  2020-03-19   0.777223       P\n",
      "331706  2020-03-19   0.774723       P\n",
      "331707  2020-03-19   0.772240       P\n",
      "331708  2020-03-19   0.766102       P\n",
      "331709  2020-03-19   0.764886       P\n",
      "331710  2020-03-19   0.763674       P\n",
      "331711  2020-03-19   0.762465       P\n",
      "331712  2020-03-19   0.761261       P\n",
      "331713  2020-03-19   0.760060       P\n",
      "331714  2020-03-19   0.755295       P\n",
      "331715  2020-03-19   0.752934       P\n",
      "331716  2020-03-19   0.749421       P\n",
      "331717  2020-03-19   0.743639       P\n",
      "331718  2020-03-19   0.736816       P\n",
      "331719  2020-03-19   0.734570       P\n",
      "331720  2020-03-19   0.732337       P\n",
      "331721  2020-03-19   0.723541       P\n",
      "331722  2020-03-19   0.705531       P\n",
      "331723  2020-03-19   0.701424       P\n",
      "331724  2020-03-19   0.699387       P\n",
      "331725  2020-03-19   0.695351       P\n",
      "331726  2020-03-19   0.693350       P\n",
      "331727  2020-03-19   0.684486       P\n",
      "331728  2020-03-19   0.655616       P\n",
      "331729  2020-03-19   0.651186       P\n",
      "331730  2020-03-19   0.642504       P\n",
      "331731  2020-03-19   0.634050       P\n",
      "331732  2020-03-19   0.625816       P\n",
      "331733  2020-03-19   0.617792       P\n",
      "331849  2020-03-19   0.789964       C\n",
      "331850  2020-03-19   0.752934       C\n",
      "331949  2020-03-19   0.797811       P\n",
      "331950  2020-03-19   0.796493       P\n",
      "331951  2020-03-19   0.787382       P\n",
      "331952  2020-03-19   0.784818       P\n",
      "331953  2020-03-19   0.777223       P\n",
      "331954  2020-03-19   0.771005       P\n",
      "331955  2020-03-19   0.768545       P\n",
      "331956  2020-03-19   0.764886       P\n",
      "331957  2020-03-19   0.762465       P\n",
      "331958  2020-03-19   0.758863       P\n",
      "331959  2020-03-19   0.755295       P\n",
      "331960  2020-03-19   0.752934       P\n",
      "331961  2020-03-19   0.751760       P\n",
      "331962  2020-03-19   0.750589       P\n",
      "331963  2020-03-19   0.732337       P\n",
      "331964  2020-03-19   0.707603       P\n",
      "331965  2020-03-19   0.695351       P\n",
      "331966  2020-03-19   0.691360       P\n",
      "331967  2020-03-19   0.655616       P\n",
      "331968  2020-03-19   0.634050       P\n",
      "332281  2020-03-20   0.794800       C\n",
      "332282  2020-03-20   0.790710       C\n",
      "332283  2020-03-20   0.788007       C\n",
      "332284  2020-03-20   0.781329       C\n",
      "332516  2020-03-20   0.798932       C\n",
      "332517  2020-03-20   0.796173       C\n",
      "332518  2020-03-20   0.794800       C\n",
      "332519  2020-03-20   0.790710       C\n",
      "332520  2020-03-20   0.789356       C\n",
      "332521  2020-03-20   0.788007       C\n",
      "332522  2020-03-20   0.786662       C\n",
      "332523  2020-03-20   0.781329       C\n",
      "332524  2020-03-20   0.780007       C\n",
      "332525  2020-03-20   0.777376       C\n",
      "332526  2020-03-20   0.774763       C\n",
      "332527  2020-03-20   0.769589       C\n",
      "332528  2020-03-20   0.768307       C\n",
      "332529  2020-03-20   0.763219       C\n",
      "332530  2020-03-20   0.755711       C\n",
      "332810  2020-03-23   0.799071       C\n",
      "332811  2020-03-23   0.792000       C\n",
      "332812  2020-03-23   0.785053       C\n",
      "333017  2020-03-23   0.799071       C\n",
      "333018  2020-03-23   0.797647       C\n",
      "333019  2020-03-23   0.796228       C\n",
      "333020  2020-03-23   0.794813       C\n",
      "333021  2020-03-23   0.793404       C\n",
      "333022  2020-03-23   0.792000       C\n",
      "333023  2020-03-23   0.790601       C\n",
      "333024  2020-03-23   0.789206       C\n",
      "333025  2020-03-23   0.787817       C\n",
      "333026  2020-03-23   0.786432       C\n",
      "333027  2020-03-23   0.785053       C\n",
      "333028  2020-03-23   0.783678       C\n",
      "333029  2020-03-23   0.782308       C\n",
      "333030  2020-03-23   0.780942       C\n",
      "333031  2020-03-23   0.779582       C\n",
      "333032  2020-03-23   0.778226       C\n",
      "333033  2020-03-23   0.776875       C\n",
      "333034  2020-03-23   0.775529       C\n",
      "333035  2020-03-23   0.774187       C\n",
      "333036  2020-03-23   0.772850       C\n",
      "333037  2020-03-23   0.771517       C\n",
      "333242  2020-03-23   0.799071       C\n",
      "333243  2020-03-23   0.797647       C\n",
      "333244  2020-03-23   0.796228       C\n",
      "333245  2020-03-23   0.794813       C\n",
      "333246  2020-03-23   0.793404       C\n",
      "333247  2020-03-23   0.789206       C\n",
      "333248  2020-03-23   0.785053       C\n",
      "333249  2020-03-23   0.782308       C\n",
      "333250  2020-03-23   0.778226       C\n",
      "333251  2020-03-23   0.776875       C\n",
      "333252  2020-03-23   0.774187       C\n",
      "333253  2020-03-23   0.764923       C\n",
      "333254  2020-03-23   0.758441       C\n",
      "333255  2020-03-23   0.745800       C\n",
      "333256  2020-03-23   0.737199       C\n",
      "333566  2020-03-24   0.799781       P\n",
      "333567  2020-03-24   0.797176       P\n",
      "333568  2020-03-24   0.792016       P\n",
      "333569  2020-03-24   0.790737       P\n",
      "333570  2020-03-24   0.789461       P\n",
      "333571  2020-03-24   0.785660       P\n",
      "333572  2020-03-24   0.784401       P\n",
      "333573  2020-03-24   0.779404       P\n",
      "333574  2020-03-24   0.778165       P\n",
      "333575  2020-03-24   0.776930       P\n",
      "333576  2020-03-24   0.774472       P\n",
      "333577  2020-03-24   0.772028       P\n",
      "333578  2020-03-24   0.767188       P\n",
      "333579  2020-03-24   0.755349       P\n",
      "333580  2020-03-24   0.753025       P\n",
      "333581  2020-03-24   0.750715       P\n",
      "333582  2020-03-24   0.748419       P\n",
      "333583  2020-03-24   0.746137       P\n",
      "333584  2020-03-24   0.742741       P\n",
      "333585  2020-03-24   0.738259       P\n",
      "333586  2020-03-24   0.728372       P\n",
      "333587  2020-03-24   0.725135       P\n",
      "333588  2020-03-24   0.724062       P\n",
      "333589  2020-03-24   0.715594       P\n",
      "333590  2020-03-24   0.713507       P\n",
      "333937  2020-03-24   0.799781       P\n",
      "333938  2020-03-24   0.797176       P\n",
      "333939  2020-03-24   0.792016       P\n",
      "333940  2020-03-24   0.786923       P\n",
      "333941  2020-03-24   0.784401       P\n",
      "333942  2020-03-24   0.783146       P\n",
      "333943  2020-03-24   0.781895       P\n",
      "333944  2020-03-24   0.779404       P\n",
      "333945  2020-03-24   0.776930       P\n",
      "333946  2020-03-24   0.772028       P\n",
      "333947  2020-03-24   0.770813       P\n",
      "333948  2020-03-24   0.769601       P\n",
      "333949  2020-03-24   0.765988       P\n",
      "333950  2020-03-24   0.764791       P\n",
      "333951  2020-03-24   0.760040       P\n",
      "333952  2020-03-24   0.758862       P\n",
      "333953  2020-03-24   0.757687       P\n",
      "333954  2020-03-24   0.755349       P\n",
      "333955  2020-03-24   0.753025       P\n",
      "333956  2020-03-24   0.750715       P\n",
      "333957  2020-03-24   0.746137       P\n",
      "333958  2020-03-24   0.743869       P\n",
      "333959  2020-03-24   0.741615       P\n",
      "333960  2020-03-24   0.740493       P\n",
      "333961  2020-03-24   0.732734       P\n",
      "333962  2020-03-24   0.731638       P\n",
      "333963  2020-03-24   0.702247       P\n",
      "333964  2020-03-24   0.569147       P\n",
      "334097  2020-03-24   0.789461       C\n",
      "334098  2020-03-24   0.784401       C\n",
      "334236  2020-03-24   0.799781       P\n",
      "334237  2020-03-24   0.792016       P\n",
      "334238  2020-03-24   0.790737       P\n",
      "334239  2020-03-24   0.789461       P\n",
      "334240  2020-03-24   0.783146       P\n",
      "334241  2020-03-24   0.781895       P\n",
      "334242  2020-03-24   0.778165       P\n",
      "334243  2020-03-24   0.775699       P\n",
      "334244  2020-03-24   0.769601       P\n",
      "334245  2020-03-24   0.760040       P\n",
      "334246  2020-03-24   0.742741       P\n",
      "334247  2020-03-24   0.741615       P\n",
      "334248  2020-03-24   0.644034       P\n",
      "334382  2020-03-24   0.799781       C\n",
      "334383  2020-03-24   0.795880       C\n",
      "334384  2020-03-24   0.790737       C\n",
      "334385  2020-03-24   0.789461       C\n",
      "334386  2020-03-24   0.783146       C\n",
      "334387  2020-03-24   0.780648       C\n",
      "334388  2020-03-24   0.778165       C\n",
      "334389  2020-03-24   0.776930       C\n",
      "334390  2020-03-24   0.774472       C\n",
      "334567  2020-03-24   0.799781       P\n",
      "334568  2020-03-24   0.798476       P\n",
      "334569  2020-03-24   0.795880       P\n",
      "334570  2020-03-24   0.792016       P\n",
      "334571  2020-03-24   0.789461       P\n",
      "334572  2020-03-24   0.784401       P\n",
      "334573  2020-03-24   0.783146       P\n",
      "334574  2020-03-24   0.779404       P\n",
      "334575  2020-03-24   0.778165       P\n",
      "334576  2020-03-24   0.776930       P\n",
      "334577  2020-03-24   0.774472       P\n",
      "334578  2020-03-24   0.769601       P\n",
      "334579  2020-03-24   0.767188       P\n",
      "334580  2020-03-24   0.764791       P\n",
      "334581  2020-03-24   0.761222       P\n",
      "334582  2020-03-24   0.760040       P\n",
      "334583  2020-03-24   0.754185       P\n",
      "334584  2020-03-24   0.753025       P\n",
      "334585  2020-03-24   0.751868       P\n",
      "334586  2020-03-24   0.749565       P\n",
      "334587  2020-03-24   0.748419       P\n",
      "334588  2020-03-24   0.747276       P\n",
      "334589  2020-03-24   0.745002       P\n",
      "334590  2020-03-24   0.743869       P\n",
      "334591  2020-03-24   0.741615       P\n",
      "334592  2020-03-24   0.734934       P\n",
      "334593  2020-03-24   0.730546       P\n",
      "334594  2020-03-24   0.722993       P\n",
      "334595  2020-03-24   0.700238       P\n",
      "334949  2020-03-25   0.798568       P\n",
      "334950  2020-03-25   0.793449       P\n",
      "334951  2020-03-25   0.792179       P\n",
      "334952  2020-03-25   0.788395       P\n",
      "334953  2020-03-25   0.785892       P\n",
      "334954  2020-03-25   0.783405       P\n",
      "334955  2020-03-25   0.779704       P\n",
      "334956  2020-03-25   0.777256       P\n",
      "334957  2020-03-25   0.776038       P\n",
      "334958  2020-03-25   0.773613       P\n",
      "334959  2020-03-25   0.772406       P\n",
      "334960  2020-03-25   0.771203       P\n",
      "334961  2020-03-25   0.770003       P\n",
      "334962  2020-03-25   0.767616       P\n",
      "334963  2020-03-25   0.764062       P\n",
      "334964  2020-03-25   0.761711       P\n",
      "334965  2020-03-25   0.755896       P\n",
      "334966  2020-03-25   0.747903       P\n",
      "334967  2020-03-25   0.746775       P\n",
      "334968  2020-03-25   0.742297       P\n",
      "334969  2020-03-25   0.740078       P\n",
      "334970  2020-03-25   0.714447       P\n",
      "334971  2020-03-25   0.712391       P\n",
      "334972  2020-03-25   0.711368       P\n",
      "334973  2020-03-25   0.709330       P\n",
      "334974  2020-03-25   0.707303       P\n",
      "334975  2020-03-25   0.706294       P\n",
      "334976  2020-03-25   0.705288       P\n",
      "334977  2020-03-25   0.704285       P\n",
      "334978  2020-03-25   0.702287       P\n",
      "334979  2020-03-25   0.682913       P\n",
      "335289  2020-03-25   0.799858       P\n",
      "335290  2020-03-25   0.798568       P\n",
      "335291  2020-03-25   0.752450       P\n",
      "335292  2020-03-25   0.751308       P\n",
      "335293  2020-03-25   0.750170       P\n",
      "335294  2020-03-25   0.746775       P\n",
      "335295  2020-03-25   0.745651       P\n",
      "335296  2020-03-25   0.743411       P\n",
      "335297  2020-03-25   0.717554       P\n",
      "335437  2020-03-25   0.798568       C\n",
      "335438  2020-03-25   0.785892       C\n",
      "335616  2020-03-25   0.798568       P\n",
      "335617  2020-03-25   0.793449       P\n",
      "335618  2020-03-25   0.792179       P\n",
      "335619  2020-03-25   0.790914       P\n",
      "335620  2020-03-25   0.785892       P\n",
      "335621  2020-03-25   0.783405       P\n",
      "335622  2020-03-25   0.778478       P\n",
      "335623  2020-03-25   0.776038       P\n",
      "335624  2020-03-25   0.773613       P\n",
      "335625  2020-03-25   0.761711       P\n",
      "335626  2020-03-25   0.759374       P\n",
      "335627  2020-03-25   0.743411       P\n",
      "335908  2020-03-25   0.788395       P\n",
      "335909  2020-03-25   0.785892       P\n",
      "335910  2020-03-25   0.782167       P\n",
      "335911  2020-03-25   0.760541       P\n",
      "335912  2020-03-25   0.755896       P\n",
      "335913  2020-03-25   0.746775       P\n",
      "335914  2020-03-25   0.742297       P\n",
      "336159  2020-03-26   0.792190       P\n",
      "336160  2020-03-26   0.790999       P\n",
      "336451  2020-03-26   0.799413       P\n",
      "336452  2020-03-26   0.798200       P\n",
      "336453  2020-03-26   0.796991       P\n",
      "336454  2020-03-26   0.793385       P\n",
      "336455  2020-03-26   0.790999       P\n",
      "336456  2020-03-26   0.785096       P\n",
      "336457  2020-03-26   0.783926       P\n",
      "336458  2020-03-26   0.770152       P\n",
      "336459  2020-03-26   0.725537       P\n",
      "336460  2020-03-26   0.701352       P\n",
      "336781  2020-03-26   0.788627       P\n",
      "336782  2020-03-26   0.770152       P\n",
      "336783  2020-03-26   0.753602       P\n",
      "336784  2020-03-26   0.751449       P\n",
      "336785  2020-03-26   0.738784       P\n",
      "337322  2020-03-27   0.794209       P\n",
      "337323  2020-03-27   0.778398       P\n",
      "337324  2020-03-27   0.777208       P\n",
      "337325  2020-03-27   0.776021       P\n",
      "337326  2020-03-27   0.767816       P\n",
      "337327  2020-03-27   0.760919       P\n",
      "337328  2020-03-27   0.758648       P\n",
      "337329  2020-03-27   0.756390       P\n",
      "337330  2020-03-27   0.754145       P\n",
      "337632  2020-03-27   0.799204       P\n",
      "337633  2020-03-27   0.795452       P\n",
      "337634  2020-03-27   0.794209       P\n",
      "337635  2020-03-27   0.791735       P\n",
      "337636  2020-03-27   0.788053       P\n",
      "337637  2020-03-27   0.781991       P\n",
      "337638  2020-03-27   0.777208       P\n",
      "337639  2020-03-27   0.776021       P\n",
      "337640  2020-03-27   0.773659       P\n",
      "337641  2020-03-27   0.759782       P\n",
      "337642  2020-03-27   0.758648       P\n",
      "337643  2020-03-27   0.754145       P\n",
      "337644  2020-03-27   0.713896       P\n",
      "337927  2020-03-27   0.799204       P\n",
      "337928  2020-03-27   0.797950       P\n",
      "337929  2020-03-27   0.796699       P\n",
      "337930  2020-03-27   0.794209       P\n",
      "338074  2020-03-27   0.794209       C\n",
      "338075  2020-03-27   0.781991       C\n",
      "338076  2020-03-27   0.772483       C\n",
      "338077  2020-03-27   0.770142       C\n",
      "338078  2020-03-27   0.768977       C\n",
      "338299  2020-03-27   0.796699       P\n",
      "338300  2020-03-27   0.794209       P\n",
      "338301  2020-03-27   0.779592       P\n",
      "338302  2020-03-27   0.778398       P\n",
      "338303  2020-03-27   0.777208       P\n",
      "338304  2020-03-27   0.776021       P\n",
      "338305  2020-03-27   0.774838       P\n",
      "338306  2020-03-27   0.773659       P\n",
      "338307  2020-03-27   0.772483       P\n",
      "338308  2020-03-27   0.770142       P\n",
      "338309  2020-03-27   0.701095       P\n",
      "338543  2020-03-30   0.798374       P\n",
      "338544  2020-03-30   0.795955       P\n",
      "338545  2020-03-30   0.793550       P\n",
      "338546  2020-03-30   0.792353       P\n",
      "338547  2020-03-30   0.789970       P\n",
      "338548  2020-03-30   0.788784       P\n",
      "338549  2020-03-30   0.784075       P\n",
      "338550  2020-03-30   0.779421       P\n",
      "338848  2020-03-30   0.798374       P\n",
      "338849  2020-03-30   0.794750       P\n",
      "338850  2020-03-30   0.781741       P\n",
      "339203  2020-03-30   0.784075       P\n",
      "339204  2020-03-30   0.751545       P\n",
      "339205  2020-03-30   0.750471       P\n",
      "339475  2020-03-30   0.784075       P\n",
      "339680  2020-03-31   0.791605       P\n",
      "339681  2020-03-31   0.790395       P\n",
      "340016  2020-03-31   0.797713       P\n",
      "340017  2020-03-31   0.792819       P\n",
      "340018  2020-03-31   0.791605       P\n",
      "340019  2020-03-31   0.787985       P\n",
      "340020  2020-03-31   0.786785       P\n",
      "340021  2020-03-31   0.783209       P\n",
      "340022  2020-03-31   0.782024       P\n",
      "340023  2020-03-31   0.773829       P\n",
      "340024  2020-03-31   0.771519       P\n",
      "340025  2020-03-31   0.762416       P\n",
      "340026  2020-03-31   0.717942       P\n",
      "340304  2020-03-31   0.749157       P\n",
      "340594  2020-04-01   0.799515       P\n",
      "340595  2020-04-01   0.798223       P\n",
      "340596  2020-04-01   0.795652       P\n",
      "340597  2020-04-01   0.790560       P\n",
      "340598  2020-04-01   0.784286       P\n",
      "340599  2020-04-01   0.779338       P\n",
      "340600  2020-04-01   0.778110       P\n",
      "340601  2020-04-01   0.772031       P\n",
      "340602  2020-04-01   0.766047       P\n",
      "340603  2020-04-01   0.762500       P\n",
      "340604  2020-04-01   0.761325       P\n",
      "340605  2020-04-01   0.760154       P\n",
      "340606  2020-04-01   0.758986       P\n",
      "340607  2020-04-01   0.757822       P\n",
      "340608  2020-04-01   0.756662       P\n",
      "340609  2020-04-01   0.755505       P\n",
      "340610  2020-04-01   0.754351       P\n",
      "340611  2020-04-01   0.752055       P\n",
      "340612  2020-04-01   0.750912       P\n",
      "340613  2020-04-01   0.745249       P\n",
      "340614  2020-04-01   0.744127       P\n",
      "340615  2020-04-01   0.738565       P\n",
      "340616  2020-04-01   0.737463       P\n",
      "340617  2020-04-01   0.712987       P\n",
      "340618  2020-04-01   0.710935       P\n",
      "340619  2020-04-01   0.709914       P\n",
      "340620  2020-04-01   0.708895       P\n",
      "340621  2020-04-01   0.707880       P\n",
      "340622  2020-04-01   0.706867       P\n",
      "340623  2020-04-01   0.705857       P\n",
      "340624  2020-04-01   0.704850       P\n",
      "340625  2020-04-01   0.703846       P\n",
      "340626  2020-04-01   0.702845       P\n",
      "340902  2020-04-01   0.798223       P\n",
      "340903  2020-04-01   0.796935       P\n",
      "340904  2020-04-01   0.795652       P\n",
      "340905  2020-04-01   0.790560       P\n",
      "340906  2020-04-01   0.788038       P\n",
      "340907  2020-04-01   0.783043       P\n",
      "341185  2020-04-01   0.790560       P\n",
      "341186  2020-04-01   0.781804       P\n",
      "341187  2020-04-01   0.778110       P\n",
      "341188  2020-04-01   0.776887       P\n",
      "341404  2020-04-02   0.799652       P\n",
      "341405  2020-04-02   0.793375       P\n",
      "341406  2020-04-02   0.784752       P\n",
      "341407  2020-04-02   0.781113       P\n",
      "341408  2020-04-02   0.779907       P\n",
      "341409  2020-04-02   0.778706       P\n",
      "341410  2020-04-02   0.777508       P\n",
      "341411  2020-04-02   0.773936       P\n",
      "341412  2020-04-02   0.769224       P\n",
      "341413  2020-04-02   0.768055       P\n",
      "341414  2020-04-02   0.765727       P\n",
      "341415  2020-04-02   0.761114       P\n",
      "341416  2020-04-02   0.759970       P\n",
      "341417  2020-04-02   0.754298       P\n",
      "341418  2020-04-02   0.753174       P\n",
      "341419  2020-04-02   0.750936       P\n",
      "341420  2020-04-02   0.748711       P\n",
      "341421  2020-04-02   0.742115       P\n",
      "341422  2020-04-02   0.738860       P\n",
      "341423  2020-04-02   0.736706       P\n",
      "341424  2020-04-02   0.723004       P\n",
      "341683  2020-04-02   0.799652       P\n",
      "341684  2020-04-02   0.797129       P\n",
      "341685  2020-04-02   0.777508       P\n",
      "341686  2020-04-02   0.765727       P\n",
      "341687  2020-04-02   0.759970       P\n",
      "341688  2020-04-02   0.748711       P\n",
      "341689  2020-04-02   0.732435       P\n",
      "341913  2020-04-02   0.799652       P\n",
      "341914  2020-04-02   0.797129       P\n",
      "341915  2020-04-02   0.795874       P\n",
      "341916  2020-04-02   0.794623       P\n",
      "341917  2020-04-02   0.789656       P\n",
      "341918  2020-04-02   0.777508       P\n",
      "341919  2020-04-02   0.765727       P\n",
      "342208  2020-04-02   0.775123       P\n",
      "342209  2020-04-02   0.761114       P\n",
      "342210  2020-04-02   0.739941       P\n",
      "342211  2020-04-02   0.711803       P\n",
      "342412  2020-04-03   0.796368       P\n",
      "342413  2020-04-03   0.783827       P\n",
      "342414  2020-04-03   0.777703       P\n",
      "342415  2020-04-03   0.748466       P\n",
      "342416  2020-04-03   0.742881       P\n",
      "342417  2020-04-03   0.737378       P\n",
      "342665  2020-04-03   0.793828       P\n",
      "342666  2020-04-03   0.792564       P\n",
      "342667  2020-04-03   0.787547       P\n",
      "342668  2020-04-03   0.785063       P\n",
      "342669  2020-04-03   0.783827       P\n",
      "342670  2020-04-03   0.765738       P\n",
      "342671  2020-04-03   0.731956       P\n",
      "342977  2020-04-03   0.797644       P\n",
      "342978  2020-04-03   0.796368       P\n",
      "342979  2020-04-03   0.792564       P\n",
      "342980  2020-04-03   0.791304       P\n",
      "342981  2020-04-03   0.788796       P\n",
      "342982  2020-04-03   0.787547       P\n",
      "342983  2020-04-03   0.783827       P\n",
      "342984  2020-04-03   0.782594       P\n",
      "342985  2020-04-03   0.777703       P\n",
      "342986  2020-04-03   0.776490       P\n",
      "342987  2020-04-03   0.770480       P\n",
      "342988  2020-04-03   0.757580       P\n",
      "342989  2020-04-03   0.751858       P\n",
      "344554  2020-04-08   0.793645       P\n",
      "344555  2020-04-08   0.791361       P\n",
      "344556  2020-04-08   0.790224       P\n",
      "344557  2020-04-08   0.789090       P\n",
      "344558  2020-04-08   0.787960       P\n",
      "344559  2020-04-08   0.786833       P\n",
      "344560  2020-04-08   0.785709       P\n",
      "344561  2020-04-08   0.784588       P\n",
      "344562  2020-04-08   0.783470       P\n",
      "344563  2020-04-08   0.782356       P\n",
      "350417  2020-04-22   0.796390       P\n",
      "355300  2020-05-04   0.693351       P\n",
      "355301  2020-05-04   0.676843       P\n",
      "359052  2020-05-13   0.732468       P\n",
      "359842  2020-05-14   0.679167       P\n",
      "359843  2020-05-14   0.663372       P\n",
      "360823  2020-05-18   0.703312       P\n",
      "360824  2020-05-18   0.686956       P\n",
      "363114  2020-05-27   0.706077       P\n",
      "363115  2020-05-27   0.690030       P\n",
      "365353  2020-06-02   0.700186       P\n",
      "365354  2020-06-02   0.684627       P\n",
      "371042  2020-06-15   0.652466       P\n",
      "371043  2020-06-15   0.638873       P\n",
      "371254  2020-06-16   0.781185       P\n",
      "372866  2020-06-18   0.741748       P\n",
      "372867  2020-06-18   0.708032       P\n",
      "373048  2020-06-18   0.677248       P\n",
      "408257  2020-09-21   0.729124       P\n",
      "409483  2020-09-24   0.721464       P\n",
      "410805  2020-09-28   0.698250       P\n",
      "412147  2020-10-01   0.751289       P\n",
      "426238  2020-11-05   0.675087       P\n",
      "440008  2020-12-11   0.691219       P\n",
      "441930  2020-12-15   0.769713       P\n",
      "441931  2020-12-15   0.754004       P\n",
      "441932  2020-12-15   0.738924       P\n",
      "441933  2020-12-15   0.724435       P\n",
      "441934  2020-12-15   0.710504       P\n",
      "441935  2020-12-15   0.684189       P\n",
      "442166  2020-12-15   0.738924       P\n",
      "443295  2020-12-17   0.702355       P\n",
      "444554  2020-12-21   0.786153       P\n",
      "444555  2020-12-21   0.769775       P\n",
      "444556  2020-12-21   0.724494       P\n",
      "444751  2020-12-21   0.710562       P\n",
      "444752  2020-12-21   0.671804       P\n",
      "449118  2021-01-05   0.745372       P\n",
      "449119  2021-01-05   0.703181       P\n",
      "470153  2021-03-01   0.780364       P\n",
      "470154  2021-03-01   0.722559       P\n",
      "470366  2021-03-01   0.696754       P\n",
      "471613  2021-03-04   0.785098       P\n",
      "471614  2021-03-04   0.738916       P\n",
      "471615  2021-03-04   0.685176       P\n",
      "472048  2021-03-04   0.738916       P\n",
      "472049  2021-03-04   0.724706       P\n",
      "472050  2021-03-04   0.711032       P\n",
      "472051  2021-03-04   0.685176       P\n",
      "472052  2021-03-04   0.661135       P\n",
      "472450  2021-03-05   0.784069       P\n",
      "472451  2021-03-05   0.686061       P\n",
      "472452  2021-03-05   0.674025       P\n",
      "472453  2021-03-05   0.662403       P\n",
      "487380  2021-04-15   0.744718       P\n",
      "487381  2021-04-15   0.719038       P\n",
      "488384  2021-04-19   0.682502       P\n",
      "488385  2021-04-19   0.671494       P\n",
      "490577  2021-04-26   0.686495       P\n",
      "490578  2021-04-26   0.675423       P\n",
      "492703  2021-05-03   0.687321       P\n",
      "492704  2021-05-03   0.676236       P\n",
      "507469  2021-06-11   0.696302       P\n",
      "507990  2021-06-14   0.709192       P\n",
      "507991  2021-06-14   0.697566       P\n",
      "508697  2021-06-15   0.758320       P\n",
      "508698  2021-06-15   0.732171       P\n",
      "513532  2021-06-28   0.692034       P\n",
      "515111  2021-07-02   0.725390       P\n",
      "517288  2021-07-12   0.718792       P\n",
      "517289  2021-07-12   0.707198       P\n",
      "520051  2021-07-16   0.697929       P\n",
      "546996  2021-09-22   0.720597       P\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_row',None)\n",
    "print(data_train[data_train['moneyness']<0.8].shape)\n",
    "print(data_train[data_train['moneyness']<0.8][['date','moneyness', 'cp_flag']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 30)\n",
      "              date  moneyness cp_flag\n",
      "16345   2013-07-15   1.682500       C\n",
      "18675   2013-09-25   1.781863       C\n",
      "21884   2013-12-16   1.786540       C\n",
      "30043   2014-07-15   1.644400       C\n",
      "38438   2015-01-12   1.655722       C\n",
      "38739   2015-01-16   2.243800       C\n",
      "48949   2015-08-21   1.677353       P\n",
      "48950   2015-08-21   1.642408       P\n",
      "48951   2015-08-21   1.608890       P\n",
      "49143   2015-08-24   1.893210       P\n",
      "49144   2015-08-24   1.721100       P\n",
      "49145   2015-08-24   1.646270       P\n",
      "49248   2015-08-24   1.992853       P\n",
      "51714   2015-09-15   1.683481       C\n",
      "57282   2015-12-14   2.021940       C\n",
      "57283   2015-12-14   1.838127       C\n",
      "63582   2016-03-11   2.022190       C\n",
      "63583   2016-03-11   1.617752       C\n",
      "71997   2016-06-14   1.660256       C\n",
      "81233   2016-09-09   2.300335       C\n",
      "81307   2016-09-09   2.127810       C\n",
      "85741   2016-10-14   2.132980       C\n",
      "105590  2017-03-14   1.971208       C\n",
      "127987  2017-08-24   1.625980       C\n",
      "129055  2017-09-01   1.651033       C\n",
      "134180  2017-10-13   2.553170       C\n",
      "143291  2017-12-11   1.899993       C\n",
      "145482  2017-12-22   2.064108       C\n",
      "146317  2017-12-29   2.228008       C\n",
      "147945  2018-01-16   1.791239       C\n",
      "147946  2018-01-16   1.633188       C\n",
      "154150  2018-02-09   1.838281       P\n",
      "154151  2018-02-09   1.775966       P\n",
      "154152  2018-02-09   1.746367       P\n",
      "154153  2018-02-09   1.663206       P\n",
      "154154  2018-02-09   1.612031       P\n",
      "154774  2018-02-09   1.746367       P\n",
      "154775  2018-02-09   1.612031       P\n",
      "165451  2018-03-22   1.652306       P\n",
      "165452  2018-03-22   1.602236       P\n",
      "165831  2018-03-23   2.588260       C\n",
      "170071  2018-04-11   1.651369       C\n",
      "170072  2018-04-11   1.601327       C\n",
      "170760  2018-04-13   2.656300       C\n",
      "182203  2018-06-11   1.854667       C\n",
      "182420  2018-06-12   1.857900       C\n",
      "197779  2018-08-31   1.934347       C\n",
      "197780  2018-08-31   1.871948       C\n",
      "197863  2018-08-31   1.706776       C\n",
      "198454  2018-09-05   1.699177       C\n",
      "200191  2018-09-14   1.760594       C\n",
      "200192  2018-09-14   1.708812       C\n",
      "200193  2018-09-14   1.659989       C\n",
      "200194  2018-09-14   1.613878       C\n",
      "201579  2018-09-19   1.615528       C\n",
      "201674  2018-09-19   1.615528       C\n",
      "210655  2018-10-24   1.609758       P\n",
      "221623  2018-12-04   1.928614       C\n",
      "224273  2018-12-14   2.599950       C\n",
      "224274  2018-12-14   2.363591       C\n",
      "227715  2018-12-21   1.666635       P\n",
      "230994  2019-01-03   1.631927       C\n",
      "250067  2019-04-11   2.888320       C\n",
      "257917  2019-05-20   1.832406       C\n",
      "258060  2019-05-21   1.909573       C\n",
      "259887  2019-05-31   1.618859       C\n",
      "262899  2019-06-14   2.062129       C\n",
      "263367  2019-06-18   1.823594       C\n",
      "263679  2019-06-18   1.716324       C\n",
      "264571  2019-06-21   1.735565       C\n",
      "265101  2019-06-24   1.732559       C\n",
      "269072  2019-07-16   1.623805       C\n",
      "271154  2019-07-26   2.631183       C\n",
      "271155  2019-07-26   2.521550       C\n",
      "271384  2019-07-29   2.157836       C\n",
      "283057  2019-09-17   1.794448       C\n",
      "283058  2019-09-17   1.646959       C\n",
      "287619  2019-10-04   2.952010       C\n",
      "287620  2019-10-04   1.968007       C\n",
      "289258  2019-10-11   2.475225       C\n",
      "289402  2019-10-14   1.977433       C\n",
      "290617  2019-10-17   1.665528       C\n",
      "290698  2019-10-18   1.659000       C\n",
      "291871  2019-10-25   1.679194       C\n",
      "291997  2019-10-25   1.633811       C\n",
      "292246  2019-10-28   2.171014       C\n",
      "293473  2019-11-04   1.620142       C\n",
      "300155  2019-12-11   1.963519       C\n",
      "300830  2019-12-13   1.920485       C\n",
      "301023  2019-12-13   1.667789       C\n",
      "301253  2019-12-13   1.760444       C\n",
      "301446  2019-12-16   2.127633       C\n",
      "301447  2019-12-16   1.934212       C\n",
      "301448  2019-12-16   1.773028       C\n",
      "302068  2019-12-17   1.749326       C\n",
      "303298  2019-12-20   1.695379       C\n",
      "303449  2019-12-20   1.610610       C\n",
      "309865  2020-01-27   1.753313       C\n",
      "319126  2020-02-28   1.846387       P\n",
      "322197  2020-03-05   1.679967       P\n",
      "322347  2020-03-06   1.651317       C\n",
      "322880  2020-03-06   1.801436       P\n",
      "322881  2020-03-06   1.748453       P\n",
      "322882  2020-03-06   1.698497       P\n",
      "322883  2020-03-06   1.651317       P\n",
      "322884  2020-03-06   1.606687       P\n",
      "323243  2020-03-09   1.831040       C\n",
      "323380  2020-03-09   2.112739       P\n",
      "323381  2020-03-09   1.961829       P\n",
      "323382  2020-03-09   1.831040       P\n",
      "323383  2020-03-09   1.771974       P\n",
      "323384  2020-03-09   1.716600       P\n",
      "323385  2020-03-09   1.664582       P\n",
      "323386  2020-03-09   1.615624       P\n",
      "324460  2020-03-10   1.695429       P\n",
      "324461  2020-03-10   1.601239       P\n",
      "325236  2020-03-11   1.612576       P\n",
      "326249  2020-03-13   2.464564       P\n",
      "326250  2020-03-13   2.357409       P\n",
      "326251  2020-03-13   2.259183       P\n",
      "326252  2020-03-13   2.213078       P\n",
      "326253  2020-03-13   2.168816       P\n",
      "326254  2020-03-13   2.126290       P\n",
      "326255  2020-03-13   2.085400       P\n",
      "326256  2020-03-13   2.046053       P\n",
      "326257  2020-03-13   2.008163       P\n",
      "326258  2020-03-13   1.971651       P\n",
      "326259  2020-03-13   1.936443       P\n",
      "326260  2020-03-13   1.902470       P\n",
      "326261  2020-03-13   1.869669       P\n",
      "326262  2020-03-13   1.837980       P\n",
      "326263  2020-03-13   1.807347       P\n",
      "327135  2020-03-13   2.259183       P\n",
      "327136  2020-03-13   2.168816       P\n",
      "327137  2020-03-13   2.126290       P\n",
      "327138  2020-03-13   2.085400       P\n",
      "327139  2020-03-13   1.936443       P\n",
      "327140  2020-03-13   1.902470       P\n",
      "327141  2020-03-13   1.869669       P\n",
      "327142  2020-03-13   1.837980       P\n",
      "327143  2020-03-13   1.807347       P\n",
      "327400  2020-03-16   1.617715       C\n",
      "327567  2020-03-16   2.169209       P\n",
      "327568  2020-03-16   1.988442       P\n",
      "327569  2020-03-16   1.947861       P\n",
      "327570  2020-03-16   1.908904       P\n",
      "327571  2020-03-16   1.835485       P\n",
      "327572  2020-03-16   1.735367       P\n",
      "327573  2020-03-16   1.704378       P\n",
      "327574  2020-03-16   1.645607       P\n",
      "327575  2020-03-16   1.617715       P\n",
      "328195  2020-03-16   2.386130       P\n",
      "328196  2020-03-16   1.947861       P\n",
      "328197  2020-03-16   1.908904       P\n",
      "328198  2020-03-16   1.835485       P\n",
      "328199  2020-03-16   1.767504       P\n",
      "328200  2020-03-16   1.735367       P\n",
      "328201  2020-03-16   1.704378       P\n",
      "328202  2020-03-16   1.674477       P\n",
      "328203  2020-03-16   1.645607       P\n",
      "328204  2020-03-16   1.617715       P\n",
      "329441  2020-03-17   1.605835       P\n",
      "329832  2020-03-17   1.686127       P\n",
      "331851  2020-03-19   1.606260       P\n",
      "332531  2020-03-20   2.095382       P\n",
      "332532  2020-03-20   1.920767       P\n",
      "332533  2020-03-20   1.843936       P\n",
      "332534  2020-03-20   1.773015       P\n",
      "332535  2020-03-20   1.707348       P\n",
      "332536  2020-03-20   1.646371       P\n",
      "333038  2020-03-23   1.721077       P\n",
      "333039  2020-03-23   1.657333       P\n",
      "334099  2020-03-24   1.631553       P\n",
      "334391  2020-03-24   1.659207       P\n",
      "334392  2020-03-24   1.631553       P\n",
      "334393  2020-03-24   1.604807       P\n",
      "335120  2020-03-25   1.650373       P\n",
      "335439  2020-03-25   1.678346       P\n",
      "335440  2020-03-25   1.623318       P\n",
      "335754  2020-03-25   1.650373       P\n",
      "338079  2020-03-27   1.815336       P\n",
      "338080  2020-03-27   1.752738       P\n",
      "338081  2020-03-27   1.694313       P\n",
      "338082  2020-03-27   1.639658       P\n",
      "339316  2020-03-30   1.641656       P\n",
      "340124  2020-03-31   1.615369       P\n",
      "344150  2020-04-07   1.611764       C\n",
      "351215  2020-04-23   1.645765       C\n",
      "361096  2020-05-19   2.435783       C\n",
      "361097  2020-05-19   1.623856       C\n",
      "361814  2020-05-21   2.457092       C\n",
      "368741  2020-06-11   2.001400       C\n",
      "368846  2020-06-11   1.667833       P\n",
      "373589  2020-06-19   2.065160       C\n",
      "374916  2020-06-23   2.609408       C\n",
      "375489  2020-06-24   1.906456       C\n",
      "375490  2020-06-24   1.794312       C\n",
      "377397  2020-06-26   1.823667       C\n",
      "398268  2020-08-27   1.883541       C\n",
      "404396  2020-09-14   1.691770       C\n",
      "405175  2020-09-15   1.700600       C\n",
      "409356  2020-09-24   1.623295       C\n",
      "409630  2020-09-24   1.623295       C\n",
      "409972  2020-09-25   1.912151       C\n",
      "415417  2020-10-12   1.767110       C\n",
      "418320  2020-10-16   1.741905       C\n",
      "421071  2020-10-26   1.619510       C\n",
      "421072  2020-10-26   1.600456       C\n",
      "421610  2020-10-27   1.832800       C\n",
      "421611  2020-10-27   1.784568       C\n",
      "422368  2020-10-28   1.721595       C\n",
      "422456  2020-10-28   1.635515       P\n",
      "423410  2020-10-30   1.634980       P\n",
      "423669  2020-10-30   1.634980       P\n",
      "424502  2020-11-02   1.655120       P\n",
      "425246  2020-11-03   1.684580       P\n",
      "425247  2020-11-03   1.604362       P\n",
      "427420  2020-11-09   1.651395       C\n",
      "428033  2020-11-10   1.611605       C\n",
      "429524  2020-11-13   1.792575       C\n",
      "441109  2020-12-14   1.677007       C\n",
      "442776  2020-12-16   2.056206       C\n",
      "443991  2020-12-18   1.854705       C\n",
      "445403  2020-12-23   1.845005       C\n",
      "445797  2020-12-24   1.851530       C\n",
      "445950  2020-12-24   1.851530       C\n",
      "446291  2020-12-28   1.624070       C\n",
      "446292  2020-12-28   1.606606       C\n",
      "446925  2020-12-29   1.961600       C\n",
      "446926  2020-12-29   1.774781       C\n",
      "447724  2020-12-31   1.788605       C\n",
      "447908  2021-01-04   1.682114       C\n",
      "448105  2021-01-04   1.947710       C\n",
      "448106  2021-01-04   1.762214       C\n",
      "448107  2021-01-04   1.608978       C\n",
      "449536  2021-01-06   2.677243       C\n",
      "452024  2021-01-12   1.659908       C\n",
      "452025  2021-01-12   1.645537       C\n",
      "453843  2021-01-15   1.712841       C\n",
      "458155  2021-01-27   1.704895       P\n",
      "458156  2021-01-27   1.630770       P\n",
      "464244  2021-02-12   1.606053       C\n",
      "465518  2021-02-17   1.687266       C\n",
      "469501  2021-02-26   1.905575       C\n",
      "469502  2021-02-26   1.814833       C\n",
      "475347  2021-03-12   1.609527       C\n",
      "480434  2021-03-25   2.443450       C\n",
      "480435  2021-03-25   2.299718       C\n",
      "480436  2021-03-25   2.057642       C\n",
      "496492  2021-05-12   2.031520       C\n",
      "498131  2021-05-14   1.630410       C\n",
      "498134  2021-05-14   1.617771       C\n",
      "535376  2021-08-26   1.788000       C\n",
      "540130  2021-09-10   1.801446       C\n",
      "540843  2021-09-10   1.938513       C\n",
      "540844  2021-09-10   1.857742       C\n",
      "540845  2021-09-10   1.621302       C\n",
      "542235  2021-09-14   1.676623       C\n",
      "549658  2021-09-28   1.741052       C\n",
      "556224  2021-10-11   1.710271       C\n",
      "562231  2021-10-26   2.287395       C\n",
      "562438  2021-10-26   1.694367       C\n",
      "572484  2021-11-22   1.614807       C\n",
      "576550  2021-11-30   1.631071       C\n",
      "579034  2021-12-03   1.620868       P\n"
     ]
    }
   ],
   "source": [
    "print(data_train[data_train['moneyness']>1.6].shape)\n",
    "\n",
    "print(data_train[data_train['moneyness']>1.6][['date','moneyness', 'cp_flag']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moneyness was not processed properly\n",
    "# follow the same approach as in literature...\n",
    "# Drop 0.8< and >1.6\n",
    "# five categories, but distinct for both call and put options;\n",
    "# deep OTM, OTM, ATM, ITM, deep ITM. order flips for both\n",
    "# write to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>) │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d_5 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m10\u001b[0m) │           \u001b[38;5;34m480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m10\u001b[0m) │            \u001b[38;5;34m40\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d_6 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m10\u001b[0m)       │           \u001b[38;5;34m840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m10\u001b[0m)       │            \u001b[38;5;34m40\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m11\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411</span> (5.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,411\u001b[0m (5.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,371</span> (5.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,371\u001b[0m (5.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> (160.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m40\u001b[0m (160.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Functional name=functional_3, built=True>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def create_model(n_params, \n",
    "                 dropout, \n",
    "                 recurrent_dropout, \n",
    "                 n_convlstm_layers = 2,\n",
    "                 hidden_activation =  tf.keras.activations.tanh, \n",
    "                 optimizer = keras.optimizers.Adam()):\n",
    "\n",
    "    # input layer\n",
    "    input_layer = layers.Input(shape= (None,5,5,1) )\n",
    "    \n",
    "    # lstm layers\n",
    "    lstm = input_layer\n",
    "    for i in range( n_convlstm_layers ):\n",
    "        lstm =  layers.ConvLSTM2D( \n",
    "            kernel_size= (1,1), \n",
    "            filters=n_params, \n",
    "            data_format= 'channels_last', \n",
    "            return_sequences = i<n_convlstm_layers-1,\n",
    "            activation=hidden_activation,\n",
    "            padding = \"same\",\n",
    "            dropout=dropout, \n",
    "            recurrent_dropout=recurrent_dropout\n",
    "        )( lstm )\n",
    "        lstm = layers.BatchNormalization()(lstm)    \n",
    "\n",
    "    output = layers.Conv2D(\n",
    "        filters=1, kernel_size=(1, 1), activation=\"linear\", padding=\"same\"\n",
    "    )( lstm )\n",
    "    output_layer = layers.Reshape((5,5))(output)\n",
    "\n",
    "    # compile\n",
    "    model = models.Model( input_layer, output_layer )\n",
    "    model.compile(\n",
    "        loss= \"MAE\",\n",
    "        optimizer=optimizer, \n",
    "    ) \n",
    "    \n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def train_model(model, \n",
    "                dataset, \n",
    "                verbose = True, \n",
    "                save : \"dir\" = False,\n",
    "                training_kwarg_overwrites : \"dict\" = {} ):\n",
    "    \n",
    "    # train until we run out of improvement\n",
    "    callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15),\n",
    "    ]\n",
    "    \n",
    "    # train model\n",
    "    training_kwargs = {\n",
    "        \"x\" : dataset[\"train\"][\"x_scaled\"],\n",
    "        \"y\" : dataset[\"train\"][\"y_scaled\"],\n",
    "        \"epochs\" : 200,\n",
    "        \"batch_size\" : 64,\n",
    "        \"verbose\" : verbose,\n",
    "        \"validation_split\" : 0.2,\n",
    "        \"callbacks\" : callbacks,\n",
    "    } \n",
    "    training_kwargs.update(training_kwarg_overwrites)\n",
    "    train_hist = model.fit( **training_kwargs )\n",
    "    \n",
    "    \n",
    "    if save:\n",
    "        Path(save).mkdir(parents=True, exist_ok=True) # make a home for the models\n",
    "        train_start, train_end = [ f( dataset[\"dates\"][\"train\"] ) for f in (min,max) ]\n",
    "        model_name = \"-\".join( date.strftime(\"%Y%m%d\") for date in [train_start, train_end] )\n",
    "        model.save( save+model_name )\n",
    "        \n",
    "    return model, train_hist\n",
    "\n",
    "model = create_model(n_params=10,dropout=0.1,recurrent_dropout=0.1,n_convlstm_layers=2)\n",
    "train_model(model, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out functional or sequential, and also, what dimension x should be,\n",
    "# and, how time is shown.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hydra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_lstm2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">221,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">577</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_lstm2d_2 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m38,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m) │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d_3 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m221,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m577\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">260,545</span> (1017.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m260,545\u001b[0m (1017.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">260,353</span> (1017.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m260,353\u001b[0m (1017.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a ConvLSTM2D model\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.ConvLSTM2D(\n",
    "        filters=32,  # Number of convolutional filters\n",
    "        kernel_size=(3, 3),  # Height and width of the convolution window\n",
    "        input_shape=(10, 64, 64, 1),  # (time_steps, height, width, channels)\n",
    "        padding='same',\n",
    "        return_sequences=True,  # Return full sequence\n",
    "        activation='relu'\n",
    "    ),\n",
    "    layers.BatchNormalization(),  # Normalize intermediate outputs\n",
    "    layers.ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        return_sequences=False,  # Only return the last output\n",
    "        activation='relu'\n",
    "    ),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(\n",
    "        filters=1,  # Final output has 1 channel\n",
    "        kernel_size=(3, 3),\n",
    "        activation='sigmoid',  # Adjust based on your task\n",
    "        padding='same'\n",
    "    )\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train\u001b[49m, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=8, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy test data\n",
    "x_test = np.random.rand(10, 10, 64, 64, 1)  # 10 samples, 10 timesteps, 64x64 grayscale\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Predictions will have shape (batch_size, height, width, channels)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_frame = tf.image.resize_with_pad(frame, target_height, target_width)\n",
    "padded_frame = np.pad(frame, ((0, pad_height), (0, pad_width), (0, 0)), mode='constant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of different sizes for each time step\n",
    "time_series = [\n",
    "    np.random.rand(32, 32, 1),  # (height=32, width=32, channels=1)\n",
    "    np.random.rand(64, 64, 1),  # (height=64, width=64, channels=1)\n",
    "    np.random.rand(48, 48, 1)   # (height=48, width=48, channels=1)\n",
    "]\n",
    "\n",
    "# Pad all frames to the maximum size (64x64 here)\n",
    "max_height, max_width = 64, 64\n",
    "padded_series = [\n",
    "    np.pad(frame, ((0, max_height - frame.shape[0]), (0, max_width - frame.shape[1]), (0, 0)), mode='constant')\n",
    "    for frame in time_series\n",
    "]\n",
    "\n",
    "# Stack into a single time-series array\n",
    "padded_series = np.stack(padded_series)  # Shape: (time_steps, max_height, max_width, channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.ConvLSTM2D(\n",
    "        filters=32, kernel_size=(3, 3), input_shape=(10, 64, 64, 1),\n",
    "        padding='same', return_sequences=True, activation='relu'\n",
    "    ),\n",
    "    layers.BatchNormalization(),  # Normalize outputs from the first ConvLSTM2D\n",
    "    layers.ConvLSTM2D(\n",
    "        filters=64, kernel_size=(3, 3),\n",
    "        padding='same', return_sequences=False, activation='relu'\n",
    "    ),\n",
    "    layers.BatchNormalization(),  # Normalize outputs from the second ConvLSTM2D\n",
    "    layers.Conv2D(\n",
    "        filters=1, kernel_size=(3, 3),\n",
    "        activation='sigmoid', padding='same'  # Adjust activation for your task\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have a trained model and initial data (e.g., X_0)\n",
    "current_input = X_0  # Initial input (shape: (1, time_steps, height, width, channels))\n",
    "\n",
    "# Number of steps ahead to predict\n",
    "num_steps = 3\n",
    "predictions = []\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Make prediction for the current time step\n",
    "    prediction = model.predict(current_input)\n",
    "\n",
    "    # Store the prediction\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    # Feed the prediction back into the model for the next step\n",
    "    # The new input is now the prediction made at this time step\n",
    "    current_input = prediction\n",
    "\n",
    "# predictions now contains Y_1, Y_2, Y_3, i.e., the next 3 predicted surfaces\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
